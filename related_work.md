# Related Work

The purpose of this chapter is to place my work in a wider context - to give the reader an idea of what type of research has previously been carried out in this area, to provide a setting.

# The State of Visualisation and Psychology Research

The stuff that has been really successful isn't really new. It's established psychology effects applied to visualisation (attention for focus and declutter, curse of knowledge, datasaurus (Boger)). What does this say about where we need to look for new knoweldge?

Correll: Are We Making Progress In Visualization Research?
and Kosara (2016) - Empire Built on Sand

Why do we need vis research?

Robert Kosara pie chart misconception work
Elting
Burns et al. (2021) - misconception about difficulty
Chart Junk
  * Beyond memorability - Borkin
  * Kopp et al. - embellishments
  * Okan et al. (2018) - labels are useful

MacDonald-Ross (1977; see Spence and Levandovsky, 1991) also cautions against making dismissive judgements about ‘expert’ advice in the absence of empirical evidence. Pie charts were used widely without expert approval, but Spence and Lewandowsky find evidence that they are useful in certain scenarios.  - relate this to Tufte
  
How much difference does it make really?
Woodin vs. South China Morning post
Titles vs. Climate Stripes
Desbarats - is it all just ‘it depends’?
So we have to acknowledge that psychology can’t tell us everything

How good is the evidence we do have?
Rensink (2021) - how not to study a visualisation

# Precision

Cleveland and McGill
Heer and Bostock
Correll et al (2012) - Comparing Averages in Time Series Data
Why shouldn't everything be a scatterplot?
Zacks and Tversky - different chart types serve different purposes
Robert Kosara pie chart misconception work
Borkin (2011) - self-report conflicts with utility of rainbow colourmap

Rensink (2021); Elliott et al. (2020) - role of vision science

Showing less precise data can make things easier to see (aggregation in timeseries) - the opposite of anscombe’s quartet
Albers/Szafir aggregation/colour

The precision work speaks to our concern with (in)accuracy - that we might be misleading others, that others may mislead us, that charts may be weak and lack clarity. But there is so much more than simply extracting values wrong.

# General Framing in Data Vis - Cognitive Bias

Zacks and Tversky - if different chart types serve different purposes, are we at risk of being mislead by the chart type
What other ways could we be mislead, not by imprecision (perceptual bias), but by cognitive bias.
Xiong proximity
Newman Scholl, Pentoney Berger, 

Does inclusion of a visualisation actually increase persuasion/trust/belief (Tal & Wansink) + failed replication

Misleading - Rogowitz et al. 1996

Hullman & Diakopoulos: Rhetoric

Taxonomies have captured the mapping between data types and visualisation types, revealing what is suitable for understanding particular datasets. 

Brust-Renck et al. (2013) - importance of intentionally selecting a message and designing chart appropriately to convey gist. 

Reyna and Brainerd (2008) - Suggest it’s not just about making humans more like computers and memorising verbatim detail, it’s about making sure the gist that they do extract captures the true nature of the information. 

# Visualisation Literacy

What would a bias-sensitive measure of data visualisation literacy look like, given what now know about bias?

Look at: CALVI: Critical Thinking Assessment for Literacy in Visualizations

How has literacy been assessed before (Okan)

Why have I chosen this specific measure?

# Truncation

To what extent is there a difference in the definitions of 'axis truncation':
  * both ends vs. one end
  * bars vs. axes
What is it about Witt’s study that means it can give such precise recommendations whereas others can’t
  
# Accessibility

# Colour

  * Schloss quantity biases
  * Schloss background colour
  * Szafir colour for different size marks

# Uncertainty

  * Kale
  * Kay
  * Correll VSUPs

# Prior Beliefs

  * Spiegelhalter pre-bunking
  * Heyer et al. 
  * Doug Markant
  * Xiong -Seeing What You Believe or Believing What You See? Belief Biases Correlation Estimation

# Text

See Zotero

# Numerical Framing

General knowledge on cognition about numbers - couple of papers summarising how good/bad we are and interesting findings. 
Non-visual perspective
What is framing generally? What does it show about how our brains represent information?
Lundquist et al. 
Link to Grice - readers/viewers make assumptions about communicative intent. They aren’t just passive receipients. 
Therefore there is a trust element - when trust is high, more likely to fail to question the delivery of the message. 
Which papers cite Brown (2008) and Borges (1974)?

Other numerical biases have been studied in a datavis context e.g. Dimara et al. 2017, 2019

Framing effects were initially primarily a reference to valence framing, but have since expanded to encompass a wider range of biases. 

# Vis theory

Grammar of graphics


  
