---
title: "Literature Review"
    
execute:
  echo: false
  warning: false
  message: false
  include: true
  
#bibliography:  
link_citations: true
---

```{r}
#| label: load-libraries
library(tidyverse)
library(maps)
library(mapproj)
library(patchwork) 
library(knitr)
library(ggimage)
library(ggpubr)
library(magick)
```

## A Brief History of Data Visualisation

Throughout history, data visualisations have provided insights on the dominant topics of the day, from science and healthcare to civil rights and warfare. Identifying the first use of data visualisation is impossible, but it is clear that humans have used graphic forms to display numerical information for millennia. For example, on a clay tablet dating from 3100-3000 BC, circles and semicircles represent the quantities of the beer rations which were used to pay workers [@macgregor_history_2010]. Other early visualisations include geographical maps and astronomical diagrams plotting the movements of the planets. The 18th Century saw the development of many common formats used today, such as bar charts, line charts, and pie charts, all of which are typically credited to William Playfair [@chen_brief_2008]. However, the late 19th Century has been described as 'The Golden Age of Statistical Graphics' [@friendly_golden_2008, pg. 13], generating innovations in the representation of large datasets.

In 1855, John Snow produced a map showing the spatial distribution of cholera deaths in an area of London by displaying a mark at the location where each victim had lived (@fig-snow). Deaths clustered near a contaminated water pump substantiated his radical claim that infected water sources spread this disease [@chen_brief_2008] This illustrates how data visualisations can be used to demonstrate vitally important patterns and relationships that were previously overlooked. In 1857, Florence Nightingale visualised fatalities in the Crimean war (@fig-nightingale), using a design known as a 'coxcomb', or 'rose diagram' [@chen_brief_2008]. Each month's death toll was represented by the size of a segment projecting from the chart's centre point. Crucially, the use of colour to distinguish between different causes of death illustrated that unsanitary conditions in hospitals were a far bigger threat to life than the battlefield [@friendly_radiant_2021]. This data visualisation was distributed widely to politicians, including the Prime Minister, promoting awareness of the magnitude of preventable deaths [@magnello_victorian_2012]. In 1861, Charles Joseph Minard plotted Napoleon's Russian invasion and subsequent retreat with an increasingly diminishing army (@fig-minard). Part map, part flow diagram, and part line chart, this data visualisation is a paragon of information density, representing six variables in a single graphic whilst telling a coherent story [@tufte_visual_1986].

```{r}
#| label: fig-snow
#| out-width: "500px"
#| fig-cap: "John Snow's Map of Cholera Deaths (1855)"
knitr::include_graphics("images/snow.png")
```

```{r}
#| label: fig-nightingale
#| out-width: "500px"
#| fig-cap: "Florence Nightingale's Rose Diagram (1857)"
knitr::include_graphics("images/nightingale.png")
```

```{r}
#| label: fig-minard
#| out-width: "500px"
#| fig-cap: "Charles Joseph Minard's Map of Napoleon's Russian Campaign (1861)"
knitr::include_graphics("images/minard.png")
```

Although their visualisations may appear to reveal major findings for the first time, none of Snow, Nightingale, or Minard used these visualisations to perform their initial analysis. Instead, these visualisations were used for the purposes of persuasion and storytelling [@kosara_storytelling_2013]. This is a testament to the effective use of data visualisations as rhetorical devices and instruments for storytelling, rather than their use as analytical tools. Furthermore, historically significant data visualisations have not always achieved the recognition and response they sought at the time. W.E.B. Du Bois' data visualisation exhibit on the oppression and development of Black Americans won prizes and medals at the 1900 Paris Exposition [@du_bois_american_1900], but was generally overlooked by the mainstream American press [@forrest_w_2018].

It is also necessary to acknowledge that the history of data visualisation is rather sparse, and to recognise *contemporary* work in this discipline [@kosara_empire_2016]. Recent innovations in software have generated visualisations with interactive or dynamic elements [@chen_brief_2008], but straightforward static visualisations have not disappeared. Indeed, one particularly successful case is the powerfully simple 'warming stripes' visualisation [@fig-warming-stripes, @ed_hawkins_2018_2018]. This design uses coloured stripes to display average global temperature from 1850 to the present, highlighting the rapid increase in recent years using increasingly darker reds. By eschewing date labels, text, and a colour legend, only the fundamental message remains. Accordingly, this visualisation has been reproduced in various unlikely settings for a data visualisation [e.g., music festivals, clothing, @kintisch_new_2019], earning a reputation as a recognisable symbol of the climate emergency.

```{r}
#| label: fig-warming-stripes
#| out-width: "500px"
#| fig-cap: "Warming Stripes by Ed Hawkins, showing average global temperature data from 1850 to 2018."
knitr::include_graphics("images/warming-stripes.png")
```

When considering famous data visualisations, both historical and contemporary, it is important to avoid making unfounded conclusions about how particular design choices may have contributed to their success. The effectiveness of these designs is undeniable, on account of their documented influence. However, whilst these examples illustrate that visualisations *can* be extremely effective, case studies alone do not provide insight into *why* they are effective. The history of data visualisation reveals the power of visualisations in communication rather than the principles of good design, and speculation about potential positive attributes is not a reliable source of knowledge. This illustrates the importance of studying data visualisations from a scientific perspective.

There is no guarantee that a well-received visualisation unanimously employs effective practices. This is illustrated by Hans Rosling's presentations on global health data [e.g., @hans_rosling_best_2006]. Research conducted subsequently has revealed variation in the efficacy of his different communication techniques. These hugely popular presentations included verbal explanations of complex animated graphics, delivered with enthusiasm and a dynamic stage presence. Empirical research using Rosling's talks as stimuli demonstrates that his narration facilitates comprehension of data visualisations [@obie_study_2019]. However, the same study found that it has no effect on memory and can elicit concerns about trustworthiness. Another study found that static visualisations of the same dataset improved understanding, but animated visualisations were more popular [@robertson_effectiveness_2008]. Furthermore, Rosling's designs also employed variable dot sizes in scatterplots, which can lead to perceptual biases [@anderson_inconsistent_2021; @hong_weighted_2021]. With so many variables involved in these presentations, more research is required to understand the components of effective storytelling with data visualisation [@kosara_storytelling_2013]. Rosling's contributions, in particular his pioneering use of narrative visualisation and his concern for intelligibility, should not be overlooked. Despite this, insight into the *effectiveness* of specific visualisation practices is best acquired through systematic study.

## Data Visualisation Formats and the Grammar of Graphics

There is no *one* way to represent a dataset visually. Developing a data visualisation involves making a large number of design choices, which can culminate in vastly different results. Chart 'types' (e.g., bar chart, pie chart, line chart) offer an easy way to categorise the broad format of a visualisation. However, these categorisations do not reflect the way that data visualisations are constructed or how they function. The 'Grammar of Graphics' [@wilkinson_grammar_2005] offers an alternative approach.

The Grammar of Graphics is a system for formally defining visualisations in terms of their underlying structure. As a *grammar*, rather than a taxonomy, it was developed in order to express the composition of any data visualisation through six components [@wilkinson_grammar_2005]. *Elements* describe both the *aesthetic attributes* which visually encode values (e.g., position, size, hue, transparency), and the *geometries* which represent those values (e.g., bar, dot, line). *Coordinate systems* describe the canvas used for representing values. For example, Cartestian coordinates use the vertical and horizontal dimensions associated with bar charts; polar coordinates use the circular mapping associated with pie charts; and map projections use a cartographic mapping associated with world maps. The other components of the Grammar of Graphics are the *data* used, *variable transformations* (e.g., mean, sum, rank), *scale transformations* (e.g., linear scale, logarithmic scale) and guides (e.g., axes, colour legends).

```{r}
#| label: fig-grammar
#| fig-scap: Eight different ways of displaying the same dataset, to illustrate the Grammar of Graphics.
#| fig-cap: Eight different ways of displaying the same dataset, to illustrate the Grammar of Graphics.
mydf <- mtcars %>%
  select(gear) %>%
  mutate(gear = case_match(gear, 
                           3 ~ 'A',
                           4 ~ 'B',
                           5 ~ 'C')) %>%
  mutate(gear = as.factor(gear)) 

mydf2 <- tibble(cat = factor(c('C', 'B', 'A')), 
                cont = c(5, 12, 15))

mymapdf <- sf::st_read(system.file("shape/nc.shp", 
                              package = "sf"), 
                  quiet = TRUE) %>%
  filter(NAME %in% c("Greene", "Lenoir", "Pitt")) %>%
  select(NAME, geometry) %>%
  arrange(NAME) %>%
  cbind(mydf2)

level_order <- c('A', 'B', 'C') 

base_plot_df2 <- ggplot(mydf2, 
                        aes(x = factor(cat,
                                       levels = rev(level_order)), 
                            y = cont,
                            fill = cat)) 

base_plot_df <- ggplot(mydf, aes(x = factor(gear, 
                                            levels = rev(level_order)), 
                                 fill = factor(gear)))

cartesian_theme <- function() {
  theme_void() +
  theme(axis.line.x = element_line(colour = 'black', 
                                            linewidth = 1, 
                                            linetype='solid'),
                 axis.line.y = element_line(colour = 'black', 
                                            linewidth = 1, 
                                            linetype='solid'),
        plot.margin = margin(1,1,1,1, "cm"))
}

bar <- base_plot_df +
  geom_bar(width = 1, colour = "black") +
  scale_y_continuous(limits = c(0, 17), expand = c(0,0)) +
  guides(fill = "none") +
  scale_fill_brewer(palette = "Set2") +
  cartesian_theme()

cxc <- bar + aes(y = sqrt(after_stat(count))) + coord_polar() + theme_void() + scale_y_continuous()

dot <- base_plot_df2 +
  geom_point(size = 3, colour = "black", shape = 21) +
  guides(fill = "none") +
  scale_y_continuous(limits = c(0, 17), expand = c(0,0)) +
  scale_fill_brewer(palette = "Set2") +
  cartesian_theme()
  
sbar <- ggplot(mydf, aes(x = factor(1), 
                         fill = factor(gear, levels = level_order))) +
  geom_bar(width = 0.5, colour = "black") + 
  guides(fill = "none") +
  scale_y_continuous(limits = c(0, 32), expand = c(0,0)) +
  scale_fill_brewer(palette = "Set2") +
  cartesian_theme()

pie <- sbar + 
  coord_polar(theta = "y") + 
  theme_void()

bar2 <- ggplot(mydf2, aes(x = factor(cat, 
                                     levels = rev(level_order)), 
                          y = cont,
                          fill = cont)) +
  geom_bar(stat = "identity", width = 1, colour = "black") + 
  guides(fill = "none") +
  scale_y_continuous(limits = c(0, 17), expand = c(0,0)) +
  scale_fill_continuous(trans = "reverse") +
  cartesian_theme()

choro <- mymapdf %>%
  ggplot() +
  geom_sf(aes(fill = cont), colour = "black", linewidth = 0.5) + 
  theme_void() +
  scale_fill_gradient(trans = 'reverse') +
  guides(fill = "none") 

bar + dot +
bar + cxc +
sbar + pie +
bar2 + choro +
plot_layout(nrow = 2,
            heights = 1) +
plot_annotation(tag_levels = 'A') &
theme(plot.tag = element_text(vjust = 2))

```

This system allows for efficient and consistent characterisation of different visualisation formats. For example, @fig-grammar shows that bar charts (A) and dot plots (B) both use the same aesthetic attribute (position) to encode values, but differ in their geometry (bar versus dot). A regular bar chart (C) is equivalent to a chart like Florence Nightingale's coxcomb (D), when using polar coordinates. Conversely, a *stacked* bar chart (E) is equivalent to a regular pie chart (F), when using polar coordinates. Visualisations can employ more than one aesthetic attribute, for example, the examples in @fig-grammar use hue to represent the different categorical values. However, it is possible to use lightness to represent different numerical values instead, with darker colours representing higher values (G). Using this aesthetic attribute, in combination with a map projection and geometries based on the shape of geographic regions, produces a choropleth map (H). This illustrates how the components can be combined in a flexible and modular manner, with many more possible visualisations of this dataset. The Grammar of Graphics has been influential in the development of a number of data visualisation design tools, including Polaris [@stolte_polaris_2002], which became Tableau, ggplot2 in R [@wickham_layered_2010], D3 [@bostock_d_2011], and Vega-Lite [@satyanarayan_vega-lite_2017].

## Data Visualisation Software and the Influence of Default Settings

Considering the *process* by which data visualisations are created is crucial for understanding this subject. Modern software has made it possible to quickly and easily produce a wide range of visualisations. However, variation across visualisation design tools affects the range visualisation formats available to users and the degree of customisation offered. For example, programming libraries, where data visualisations are created by writing lines of code (e.g., ggplot2 in R, plotly in Python) typically offer more options and greater control than simple point-and-click software (e.g., Microsoft Excel). Different visualisation design tools also provide different specialised capabilities. For example, Tableau is often used for business intelligence applications, such as building dashboards [@hutchison_storytelling_2013], D3 was developed for designing visualisations for the web [@bostock_d_2011], VegaLite was developed for generating interactive visualisations [@satyanarayan_vega-lite_2017], and ggplot2 was developed for use within a data analysis workflow [@wickham_ggplot2_2011].

What is possible and practicable using a particular piece of software will influence a designer's choices, which may in turn affect viewers' interpretations. However, visualisation software also initially imposes particular properties on a visualisation, through its default settings. For example, a pie chart, prior to customisation, will present segments in a particular order, using a particular set of colours. Even when it is *possible* to reject default designs, they can be highly influential, because they will remain unchanged when it is unclear *how* or *why* they should be altered [@shah_policy_2006].

However, existing default settings in data visualisation are not always suitable. For example, by default, software for creating line charts typically employs y-axes which are constrained to the range of the data. Therefore, the highest and lowest values are presented at the chart's extremes, impeding viewers' ability to gauge the magnitude of the difference. When representing categorical values with colour, designers can improve viewers' performance by rejecting defaults in favour of colours which correspond semantically with plotted data [e.g., yellow for banana, @lin_selecting_2013]. When representing continuous values with colour, rainbow colour palettes are a popular choice [@ware_rainbow_2023]. However, alternative colour palettes have been employed as defaults in attempts to avoid issues in perception associated with the rainbow colour palette [@reda_rainbows_2021].

Default settings can also cause issues in the generation of visualisations for exploratory analysis [@correll_looks_2019]. These visualisations are used to understand the characteristics of a dataset prior to formal statistical analysis. For example, histograms are used to visualise the shape of a univariate distribution. The algorithm used to produce histograms in R and D3 assumes by default that the data are normally-distributed. Consequently, abnormalities in non-normal data can be 'smoothed-over', preventing viewers from identifying them. Dot plots, another format for visualising distributions, display each individual value using a dot. In R and Tableau, by default, these dots have no translucency. This can result in many overlapping dots in close proximity, impeding a viewer's ability to differentiate between areas with different densities. This demonstrates that default settings are not *always* inappropriate. However, when default settings are *agnostic* regarding the characteristics of plotted data, unquestioning use of default settings can conceal relevant aspects of a dataset.

Although the above research exposes issues with some default settings, they are certainly not exclusively harmful. For example, one default setting used by Microsoft Excel is 'redundant encoding', where individual data points are represented using different shapes *and* different colours (e.g., blue diamonds and green triangles). Experimental work has observed that whilst this technique does not confer benefits in some tasks [@gleicher_perception_2013], it improves viewers' performance in other tasks [@nothelfer_redundant_2017]. Empirical research is important in order to identify how default settings may be beneficial or detrimental. Indeed, researchers in data visualisation often suggest that their findings may inform the development of default settings [e.g., @heer_crowdsourcing_2010; @xiong_visual_2021; @kerns_two_2021]. Several experiments in this thesis were designed to explore the consequences of default settings.

## Popular Guidance on Effective Data Visualisation Design

Our understanding of how people interpret data visualisations (and subsequent guidance) is built on shaky foundations. Some received wisdom has not been empirically tested at all, other claims have been discredited or confirmed only recently [@kosara_empire_2016]. Consequently, it is not always clear where evidence ends and opinion starts; intuition and unsubstantiated statements make for "visualisation folklore" [@correll_are_2022, pg. 3].

Statistician Edward Tufte is a source of widely-cited advice on the design of data visualisations, which he has articulated in popular books such as *The Visual Display of Quantitative Information* [@tufte_visual_1986]. One famous contribution is the 'lie-factor', which attempts to quantify the degree of misrepresentation in charts that distort data. For example, plotting values using two dimensional images exaggerates differences between values, because perceived size is determined by an image's entire *area*, not just its *height*. Consequently, in @fig-lie-factor, which appears to show a 42 percentage point difference, dividing by the real numerical difference of 15 percentage points generates a lie-factor of 2.8, compared to an ideal score of 1. However, Tufte's criteria proposed for diagnosing *substantial* distortion (less than 0.95 or more than 1.05) are based on speculation, rather than scientific evidence [@beattie_measurement_2002]. In similarly arbitrary guidance, @tufte_visual_1986 suggests that a dataset of 20 or fewer observations should be presented in a table, rather than a data visualisation. However, a subsequent empirical experiment has revealed that pie charts elicited more accurate responses than tables for proportion judgements involving only three observations [@spence_displaying_1991].

```{r}
#| label: fig-lie-factor
#| out-width: "500px"
#| fig-asp: 1
#| fig-scap: "A reproduction of a data visualisation used by Tufte (1986) to illustrate the 'lie-factor', originally published in the Los Angeles Times."
#| fig-cap: "A reproduction of a data visualisation used by Tufte (1986) to illustrate the 'lie-factor', originally published in the Los Angeles Times. The final value of 12% is a 15 percentage point decrease from the first value of 27%. However, Tufte's lie-factor of 2.8 indicates that this reduction is perceived as a 42 percentage point decrease."
df_img <- data.frame(year = c("1964", "1975", "1990"),
                     year2 = c(1.2, 3.25, 4.6),
                     image = "images/doctor.png")
#from https://pixabay.com/vectors/doctor-robe-medicine-medical-6207110/
#resized to have same dimensions as Los Angeles Times original
label_size <- 3

ggplot(df_img, aes(x = rev(year2), y = 0, image = image)) +
  geom_hline(yintercept = 0.9) +
  scale_x_continuous(position = "top", 
                     limits = c(-0.2, 4.6),
                     expand = c(0,0)) +
  scale_y_continuous(limits = c(-1,1), 
                     expand = c(0,0)) + 
  geom_image(size = rev(c(1, 16/27, 12/27)), by="height")+
  scale_size_identity() +
  labs(title = "THE SHRINKING FAMILY DOCTOR",
       subtitle = "In California",
       x = "Percentage of Doctors Devoted Solely to Family Practice",
       y = NULL) +
  theme(#text = element_text(family="Roboto Condensed"),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5, face="bold", size = 11),
        plot.subtitle = element_text(hjust = 0.5, face="bold", size = 9.5),
        axis.title.x = element_text(size = 8),
        aspect.ratio = 1.5,
        plot.margin = margin(0.5, 1, 1, 0.5, "cm"),
        plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white")
        ) +
  coord_cartesian(clip = "off") +
  geom_text(label = c("1964", "1975", "1990"),
            x = c(0,3.25,4.6),
            y = 0.97,
            #family="Roboto Condensed",
            size = label_size) +
  geom_text(label = c("27%", "16.0%", "12.0%"),
            x = c(0,3.25,4.6),
            y = 0.83,
            #family="Roboto Condensed",
            size = label_size,
            fontface = "bold") +
  geom_text(label = c("1: 2,247 Ratio to Population", "1: 3,167", "1: 4,232"),
            x = c(-0.2,3.25,4.6),
            y = c(-1.05, -0.65, -0.5),
            #family="Roboto Condensed",
            size = label_size,
            hjust = c(0, 0.5, 0.5)) +
  geom_text(label = c("8,023 Doctors", "6,694", "6,212"),
            x = c(1.1,3.25,4.6),
            y = c(-1.15, -0.75, -0.6),
            #family="Roboto Condensed",
            size = label_size,
            fontface= "bold")

```

Tufte also advocates for minimalism in the design of data visualisations. His recommendation to maximise the 'data-ink ratio' involves maximising the proportion of ink (i.e., pixels) used to depict the data itself and minimising inessential elements [@tufte_visual_1986]. However, this notion is vague and prone to excessive simplicity. Redundant features can serve to minimise error [@tversky_cognitive_1997], with 'redundant' tick marks on axes required for accurately extracting numerical values [@kosslyn_graphics_1985]. The qualifier "within reason" [@tufte_visual_1986, pg. 96] is an imprecise addition to this guidance, whereas empirical research can identify where extreme sparseness unnecessarily biases interpretations [@stock_box_1991; @gillan_minimalism_1994].

Consistent with his minimalistic approach, Tufte's recommendation to eliminate 'chartjunk' involves avoiding the use of distracting visual embellishments, which range from excessive gridlines to artistic decoration [@tufte_visual_1986]. However, there is mixed evidence regarding the harm caused by 'chartjunk' [@franconeri_science_2021]. However, condemning chartjunk remains popular, not just on aesthetic grounds, but also due to the rhetorical qualities of minimalist designs, which imply a straightforward, unbiased presentation of data [@kosara_empire_2016; @kennedy_work_2016].

Researchers argue that Tufte's recommendations for minimalistic designs do not account for human cognitive processing [@wilkinson_grammar_2005; @tergan_representational_2005]. More generally, he has been criticised for failing to support his claims with empirical evidence [@feldman-stewart_perception_2000]. Instead, his guidance is underpinned by a large collection of example visualisations taken from various sources. Therefore, Tufte's principles might assist in describing common features of some successful visualisations, rather than serving as definitive rules [@kindlmann_algebraic_2014]. Rigorous data visualisation research is required to fill gaps in knowledge and generate a reliable evidence-base.

## Empirical Research on Data Visualisation

Visualisation research takes many forms. Empirical studies on data visualisation have employed a range of techniques, including controlled experiments, usability tests, interviews, observations, and case studies, and have focused variously on perception, cognition, exploratory data analysis, and user experience [@lam_empirical_2012]. Experimental psychology studies on data visualisation are particularly valuable because they generate fundamental evidence on *how* visualisations are interpreted. Considering human interpretation in visualisation research is crucial for generating generalisable knowledge. Inadequate best practice recommendations indicate insufficient understanding of psychological mechanisms. However, progress can be slow, since theories about cognitive and perceptual processes are built through cumulative work [@chen_huge_2020]. Existing psychological research confers benefits in the form of related empirical work, as well as contributing established methods and theories [@correll_are_2022; @rensink_how_2021].

Several studies illustrate that preferences and introspection are not always a reliable source of information on effective visualisation practices. For example, an experiment exploring physicians' judgements about clinical trials found that icon arrays resulted in the most accurate judgements, compared to tables, pie charts, and bar charts [@elting_influence_1999]. However, none of the 34 physicians in the sample preferred this format. In another study, medical students almost unanimously preferred visualisations with a rainbow colour scheme, but made fewer errors when using a diverging (e.g., red-blue) colour scheme [@borkin_evaluation_2011]. Furthermore, tables of values are favoured over visualisations in certain tasks where visualisations actually offer significant benefits [@saket_task-based_2019] and certain statistical map designs are preferred over others despite conferring no performance advantages [@mendonca_testing_2014]. Participants in Burns et al.'s [-@burns_designing_2021] study estimated that pictographs took longer to understand compared to equivalent visualisations without icons. However, this self-report measure was at odds with recorded response times, which indicated no differences between visualisations types. Many authors suggest that preferences are influenced by familiarity, rather than effectiveness. Measuring preferences provides valuable insight into people's engagement with different visualisations. However, such opinions must be treated appropriately, not used to inform conclusions about efficacy.

@rensink_how_2021 presents recommendations for generating useful findings in data visualisation research. Using a single task, and manipulating a single feature of interest, over multiple trials, assists in identifying underlying mechanisms. Integrating explanations from prior research helps ensure explanations of mental processes are sufficiently detailed. Other important but frequently overlooked matters include appropriate counterbalancing, reporting effect sizes, and acknowledging individual differences.

There are a multitude of variables that can be manipulated to gain insight into visualisations. Criticisms are sometimes levelled at studies with particularly high or low levels of experimental control. However, researchers must strike an appropriate balance between ecological validity and precision [@chen_survey_2020]. Choosing suitable tasks for participants requires a similar trade-off [@suh_inferential_2022].

Vision sciences offer a variety of paradigms for assessing various aspects of human performance in visualisation tasks. For example, experiments may evaluate accuracy (by comparing responses to a correct answer), precision (by quantifying variability in responses), or processing speed [by measuring reaction times, @elliott_design_2020]. However, chosen methods must be appropriate for a research question. Whereas methods from vision-sciences are typically concerned with performance in low-level perceptual tasks, other research focuses on decision-making [@padilla_decision_2018] or *message*-level interpretations [@pandey_how_2015]. The latter concerns overall assessments of data, such as whether a difference is large or small, rather than the ability to extract specific values. This is also referred to as *gist* [@reyna_fuzzy-trace_1991].

## Perceptual Precision in Data Visualisations

Identifying gaps in our understanding of the psychology of data visualisations requires knowledge of prior lines of inquiry and established findings. Arguably the most influential study in the field of data visualisation is Cleveland and McGill's [-@cleveland_graphical_1984] investigation of elementary perceptual processes involved in viewing visualisations. This study sought to establish how *precisely* viewers can represent different graphical properties used to encode data (e.g., position, length, angle, etc.). For each encoding type, participants identified which of two marks conveyed the smaller value, and estimated the difference in size as a percentage. Subsequent ranking based on the magnitude of participants' errors produced a hierarchy of visual encoding channels. Since position-encoding produced smaller errors than both length- and angle-encoding, this suggests that viewers will represent data most precisely when it is encoded using position on a common (aligned) scale.

This study's findings have endured replication [@heer_crowdsourcing_2010] and enthusiasm for perceptual precision has inspired a great deal of important research in this field. This research spans visual processing of proportion [@spence_displaying_1991; @hollands_judging_1998], variance [@stock_box_1991], correlation [@harrison_ranking_2014; @hong_weighted_2021], and other basic processes, such as visual comparison [@simkin_information-processing_1987; @zacks_reading_1998] and colour discrimination [@szafir_modeling_2018]. The study has also influenced development of software for automating visualisation design [@mackinlay_automating_1986] and simulating visualisation comprehension [@lohse_cognitive_1993]. However, to consider perceptual precision as the *only* relevant concern in data visualisation design is unwarranted; many additional factors require consideration.

## Beyond Perceptual Precision

Optimally-precise visual cues are not always employed when viewing visualisations. Viewers are sensitive to other task-irrelevant visual cues, which can lead to inaccurate judgements about plotted data [@yuan_perceptual_2019]. In particular tasks, precision can actually hinder, rather than facilitate, judgements. For example, because perceptual averaging benefits from a lower spatial frequency, less precise colour encoding offers *greater* efficiency than more precise position encoding [@correll_comparing_2012], see @fig-noise-example. Furthermore, effective decision-making under uncertainty does not necessarily correspond to precision in probability estimation, because of the differences in mental processing associated with these two distinct tasks [@kale_visual_2020].

```{r}
#| label: fig-noise-example
#| out-width: "500px"
#| fig-asp: 0.4
#| fig-scap: Visualisations used to demonstrate greater perceptual averaging ability for colour encoding (low spatial frequency), than position encoding (high spatial frequency).
#| fig-cap: Visualisations used to demonstrate greater perceptual averaging ability for colour encoding (low spatial frequency), than position encoding (high spatial frequency). Participants more easily identified the month with the highest average temperature (August), in the colour bar visualisation, than a line chart showing the same data. Adapted from Correll et al. (2012).
noisedata <- read_csv("images/noisedata1.csv")

noisedata_summary <- noisedata %>%
  group_by(months) %>%
  summarise(mean = mean(y)) %>% arrange(mean)

# Specify custom axis tick positions and labels
custom_ticks <- seq(from = 11.5, to = 276, by = 23)
custom_labels <- substr(month.name, 1, 3)

# Convert custom ticks and labels to a named character vector
custom_ticks_labels <- setNames(custom_labels, custom_ticks)

baseplot_noise <- noisedata %>%
  ggplot(aes(y = y, x = x)) +
  scale_x_continuous(
    breaks = custom_ticks,
    labels = custom_ticks_labels,
    limits = c(1, 276), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 100), expand = c(0, 0)) +
  theme_grey(base_size = 7) +
  theme(
    panel.background = element_rect(color = "black", linewidth = 1, fill = NA),
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  ) +
  labs(x = NULL, y = NULL) +
  coord_fixed(ratio = 2)

noise_line <- baseplot_noise +
  geom_vline(xintercept = seq(1, 276, 23),
             color = "black",
             linewidth = 0.8) +
  geom_line() +
  theme(panel.border = element_rect(colour = "black", fill=NA, linewidth=1))

noise_color <- baseplot_noise +
  geom_vline(data = noisedata,
             aes(xintercept = x, color = y),
             linewidth = 1.2) +
  scale_color_gradient2(low = "blue", mid = "beige", high = "red", midpoint = 50) +
  geom_vline(xintercept = seq(1, 276, 23),
             color = "black",
             linewidth = 0.8) +
  theme(panel.border = element_rect(colour = "black", fill=NA, linewidth=1))

noise_line + noise_color
```

Furthermore, the choice of graphical encodings employed in a data visualisation can influence the *type* of interpretation it elicits. For example, viewers are more likely to refer to trends when describing line graphs and discrete differences when describing bar charts [@zacks_bars_1999]. Similarly, *production* of bar charts and line charts is also influenced by whether a discrete or continuous relationship is specified in the brief. Design choices also influence beliefs about the distribution of underlying data, when presenting average values [@newman_bar_2012]. Compared to a data point positioned 'outside' a bar, a data point positioned 'inside' a bar is more likely to be considered part of the underlying data (see @fig-within-bar). However, displaying only confidence intervals eliminates this bias [@pentoney_confidence_2016]. This accords with the notion that viewers' cognitive associations between visual features and abstract characteristics of data are important in data visualisation design. Through common metaphors (e.g., hierarchy and vertical position), aspects of a design may offer *affordances*, carrying connotations which encourage particular interpretations [@xiong_reasoning_2022; @ziemkiewicz_shaping_2008; @kindlmann_algebraic_2014].

```{r}
#| label: fig-within-bar
#| out-width: "500px"
#| fig-scap: "Examples of data points positioned 'inside' and 'outside' a bar showing an average value, and the equivalent plots with confidence intervals."
#| fig-cap: "Examples of data points positioned 'inside' and 'outside' a bar showing an average value, and the equivalent plots with confidence intervals. The data point (grey circle) more likely to be considered part of the underlying data in A than B, but is equally likely to be considered part of underlying data in C and D. Adapted from Newman and Scholl (2012) and Pentoney and Berger (2016), from simplified versions of experimental stimuli."

wb <- tibble(x = c("A", "B", "C"), y = c(0, 80, 0))
ob <- tibble(x = c("A", "B", "C"), y = c(0, 40, 0))

cartesian_theme <- function() {
  theme_void() +
  theme(axis.line.x = element_line(colour = 'black',linewidth = 1, linetype='solid'),
        axis.line.y = element_line(colour = 'black', linewidth = 1, linetype='solid'),
        plot.margin = margin(0.1,0.1,0.1,0.1, "cm")) 
  }

within_bar <- wb %>%
  ggplot(aes(x = x, y = y)) +
  geom_col(fill = "black") +
  cartesian_theme() +
  scale_y_continuous(
    limits = c(0, 100), expand = c(0, 0)) +
  geom_point(aes(x = "B", y = 60), size = 4,
             colour = "darkgrey") +
  coord_fixed(ratio = 0.07)

within_CI <- wb %>%
  ggplot(aes(x = x, y = y)) +
  geom_col(fill = "white") +
  cartesian_theme() +
  scale_y_continuous(
    limits = c(0, 100), expand = c(0, 0)) +
  geom_point(aes(x = "B", y = 60), size = 4,
             colour = "darkgrey") +
  geom_errorbar(aes(x = "B"), 
                ymin = 70, ymax = 90,
                width = 0.7,
                linewidth = 0.6) +
  coord_fixed(ratio = 0.07)

outside_bar <- ob %>%
  ggplot(aes(x = x, y = y)) +
  geom_col(fill = "black") +
  cartesian_theme() +
  scale_y_continuous(
    limits = c(0, 100), expand = c(0, 0)) +
  geom_point(aes(x = "B", y = 60), size = 4,
             colour = "darkgrey") +
  coord_fixed(ratio = 0.07)

outside_CI <- ob %>%
  ggplot(aes(x = x, y = y)) +
  geom_col(fill = "white") +
  cartesian_theme() +
  scale_y_continuous(
    limits = c(0, 100), expand = c(0, 0)) +
  geom_point(aes(x = "B", y = 60), size = 4,
             colour = "darkgrey") +
  geom_errorbar(aes(x = "B"), 
                ymin = 30, ymax = 50,
                width = 0.7,
                linewidth = 0.6) +
  coord_fixed(ratio = 0.07)

within_bar + outside_bar + within_CI + outside_CI +
plot_layout(nrow = 1,
            heights = 1) +
plot_annotation(tag_levels = 'A') &
theme(plot.tag = element_text(vjust = 2))

```

Attention is another important factor in the comprehension of data visualisations. Complex tasks requiring selective attention can cause distinctive patterns in non-focal data to be completely overlooked [@boger_jurassic_2021]. Features of data mentioned in textual summaries are over-weighted in viewers' mental representations, causing difficulty in the ability to assume the perspective of a na√Øve viewer [@xiong_curse_2019]. In addition, the salience of vertical bars may be responsible for erroneous judgements of differences between histograms with identical distributions [@lem_interpreting_2014]. As a solution, explicitly encoding differences between pairs of values can facilitate recognition of relevant patterns [@nothelfer_measures_2020] and highlighting particular attributes can facilitate recall [@ajani_declutter_2021].

Simply conveying information is not the only purpose of data visualisations, since they also influence recall, opinion-formation, and decision-making [@bertini_why_2020]. As illustrated above, a large number of cognitive biases affect these aspects of the mental processing of data, as well as several others, including causal reasoning and assessment of hypotheses [@dimara_task-based_2020]. Whilst it is necessary to consider the precision of elementary perceptual processes, that alone is not sufficient for a comprehensive understanding of how data visualisations function [@bertini_why_2020].

## Manipulating Axes in Data Visualisations

Understanding how inaccurate impressions arise provides insight into the mechanisms involved in interpreting data visualisations. This, in turn, can inform recommendations for effective design. A prominent topic in the literature on misleading visualisations is axis truncation. This typically refers to the practice of employing a y-axis which commences with a non-zero value [@correll_truncating_2020] though may also be considered any reduction at either extreme of an x- or y-axis [@pandey_how_2015]. @fig-truncation-examples shows examples of truncated and non-truncated y-axes in line and bar charts.

```{r}
#| label: fig-truncation-examples
#| fig-scap: Examples of truncated and non-truncated line and bar charts, showing the same data.
#| fig-cap: Examples of truncated and non-truncated line and bar charts, showing the same data. The visual difference between values appears larger in the truncated version, compared to the non-truncated version due to the smaller range of values on the y-axis.

vals <- c(48, 52)
cats <- c('A', 'B') 

mydf <- tibble(vals, cats)

baseplot <- mydf %>% 
   ggplot(aes(x = cats, y = vals, group = 1)) +
   labs(x = NULL, y = NULL) +
   theme_minimal(base_size = 12) +
   theme(panel.grid.major.x = element_blank(),
         plot.caption=element_text(hjust=0.5))

 
line_trunc <- baseplot + 
  coord_cartesian(ylim = c(46, 54), 
                xlim = c(0.5, 2.5),
                expand = F) +
  geom_path(linewidth = 1) +
  labs(caption = 'Truncated\nLine Chart')

bar_trunc <- baseplot + 
  coord_cartesian(ylim = c(46, 54), 
                  xlim = c(0.5, 2.5),
                  expand = F) +
  geom_col(width = 0.3, fill = "black") +
  labs(caption = 'Truncated\nBar Chart')

line_full <- baseplot + 
  coord_cartesian(ylim = c(0, 100),
                  xlim = c(0.5, 2.5),
                  expand = F) +
  geom_path(linewidth = 1) +
  labs(caption = 'Non-Truncated\nLine Chart')

bar_full <- baseplot + 
  coord_cartesian(ylim = c(0, 100),
                  xlim = c(0.5, 2.5),
                  expand = F) +
  geom_col(width = 0.3, fill = "black") +
  labs(caption = 'Non-Truncated\nBar Chart')

line_trunc + line_full + bar_trunc + bar_full +
  plot_layout(nrow = 1) 
```

There is considerable evidence that axis limits influence interpretations of data. The majority of research on this topic has focused on how constraining the range of an axis, and thus increasing the physical distance between plotted values, increases the perceived magnitude of the difference between those values. For example, one study reports that accountants appraising financial performance using line and bar charts interpreted plotted increases as larger when these increases were depicted using a truncated y-axis [@taylor_misleading_1986]. Similarly, bar charts employing truncated axes biased students' investment decisions [@arunachalam_impression_2002]. Students were more likely to select a less-successful company when a truncated chart exaggerated that company's growth rate, compared to when a non-truncated chart was used. An online experiment also observed that differences between values were considered larger when truncated bar charts were used [@pandey_how_2015]. This experiment examined message-level representations of data by framing questions in terms of subject matter (e.g., access to safe drinking water) rather than graphical elements (e.g., difference in bar length). Other axis manipulations, such as log-scales [@romano_scale_2020], inverted scales [@woodin_conceptual_2022, @pandey_how_2015], and expanded axes in scatterplots [@cleveland_variables_1982] also influence judgements about data.

Risk communication research has independently generated similar findings about axis truncation. Because many hazards cannot be completely avoided, data visualisations are often used to contrast the levels of risk associated with two scenarios (e.g., an intervention vs. no intervention). Thus, assessments of 'risk reduction' are essentially judgements about the magnitude of difference between two values. For example, one experiment compared stacked bar charts, which include additional information on the total number of individuals at risk, to bar charts displaying only the number of individuals *affected* [@stone_foregroundbackground_2003]. The latter design increased the bars' visual disparity, and subsequently increased impressions of the magnitude of difference.

The physical distance between data points consistently biases interpretations of the magnitude of difference in spite of attention to actual numerical values and also design features intended to highlight truncation [@correll_truncating_2020]. Bias is diminished, but still observed, following explicit warnings about errors in judgement due to y-axis truncation. This suggests that this effect is largely automatic, and does not primarily occur due to insufficient engagement of cognitive capabilities [@yang_truncating_2021].

Researchers have also explored individual differences in interpretations of data presented using truncated axes. One study observed no association between participants' susceptibility to bias due to axis truncation in bar charts and their data visualisation literacy [@yang_truncating_2021]. Conversely, another experiment suggests that the effect of axis truncation on subjective judgements and quantitative estimates in line charts disappears when accounting for data visualisation literacy [@driessen_misleading_2022]. However, in the latter experiment, low variability in observed data visualisation literacy levels raised concerns about the sensitivity of the scale used to measure data visualisation literacy.

@pandey_how_2015 and @yang_truncating_2021 propose that this bias could arise due to the dominance of first impressions during translation from graphical schemata [@pinker_theory_1990] to a 'real-world' conceptual understanding [see also, @carpenter_model_1998, @tversky_judgment_1974]. Additionally, @yang_truncating_2021 suggest that viewers' beliefs about the communicative intent of a designer could play a role in viewers' interpretations. Under Grice's *Co-operative Principle* [@grice_logic_1975], communicative contributions in conversation are assumed to be truthful, relevant, clear, and sufficiently informative. Extrapolating this principle to data visualisations, viewers might infer that differences between values must be genuinely large if they appear large, because they would otherwise not be presented as such.

In *How to Lie With Statistics*, @huff_how_1993 suggests that axis truncation creates a false impression of plotted data. This practice has been labelled 'deceptive' for both bar and line charts [@lauer_deceptive_2020]. Furthermore, a tool for automatically identifying and correcting misleading line charts extends y-axes to include zero whenever this value is omitted from the original chart [@fan_annotating_2022].

Recent work has presented an alternative perspective on this controversial practice. Non-truncated axes can obscure significant differences just as easily as truncated axes can exaggerate inconsequential differences. The appropriate magnitude to convey depends on what constitutes an important difference in the data at hand [@correll_truncating_2020]. Indeed, *failing* to truncate an axis could be considered misleading in certain circumstances [@wainer_how_1984]. @yang_truncating_2021 suggest that effective designs will ensure that a viewer's immediate characterisation of plotted data closely corresponds to their interpretation following a detailed inspection. Acknowledging that differences must be depicted in proportion to their significance, [@witt_graph_2019] reports that axes spanning approximately 1.5 standard deviations provide a balance between sensitivity and bias in fields with standardised effect size measures, such as psychology. Unfortunately, different domains will not necessarily share the same notion of what amounts to a meaningful difference. Choices regarding axis ranges are ultimately designers' unavoidable decisions [@correll_truncating_2020].

Finally, although line charts and bar charts are equally susceptible to biases due to truncation [@correll_truncating_2020; @witt_graph_2019], there may be reason to treat them differently. Truncation distorts the mapping between a bar's extent and the quantity it represents, but the free-floating position-encoding used in line charts does not convey quantity in the same manner, providing immunity against such distortion [@bergstrom_misleading_2017]. Therefore, whilst starting a bar chart's axis at zero cannot guarantee that differences between values are depicted appropriately, this does ensure adherence to a fundamental aspect of visualisation design. Alternatively, to avoid this trade-off, quantitative data with discrete categories can be plotted using position-encodings only (e.g., dot plots rather than bar charts).

## Misleading Data Visualisations

Some misleading visualisations prevent viewers from accurately extracting numerical information. However, research on axis truncation illustrates that misleading visualisations may also interfere with *subjective* judgements. A line chart may precisely represent a dataset's numerical properties yet generate a distorted impression of the magnitude of a trend. The latter is revealed not by assessing viewers' *performance*, but their *interpretations* [@stone_effects_2015].

Influencing subjective judgements may still be considered a *misleading* practice because a dishonest framing of information could elicit an unreliable interpretation which would differ from the same viewer's better-informed perspective. For example, an increase may initially appear small, but may be interpreted as large when depicted in the context of genuinely meaningful differences. Not all aspects of deceptive design are *inherently* misleading, and deceptiveness can be context-dependent. Comparing examples of 'misleaders' from Ge et al.'s [-@ge_calvi_2023] design space helps illustrate this distinction. 'Concealed uncertainty' and 'cherry-picking' refer to unambiguously deceptive practices, whereas 'aggregation' and 'scale range' must be preceded by the word *inappropriate* in order to convey their capacity to deceive.

## Data Visualisation Literacy

Understanding individual differences in the ability to comprehend data in visualisations is important for understanding the psychology of data visualisations [@boy_principled_2014]. Research on this topic requires reliable tools for measuring data visualisation literacy.

Galesic and Garcia-Retamero's 13-item test [-@galesic_graph_2011] is based on Friel et al.'s [-@friel_making_2001] hierarchy of skills for interpreting visualisations, which ranges from comprehension to extrapolation. Research has demonstrated that this scale helps to predict whether a graphical representation will facilitate understanding of risk information [@okan_individual_2012]. A different 53-item test employs a wide range of data visualisation formats, and higher scores are positively associated with both numeracy and need for cognition [@lee_correlation_2019].

Research on data visualisation literacy has tended to focus on interpretation of well-designed charts [@ge_calvi_2023]. However, the ability to detect [@camba_identifying_2022] and make sense of [@ge_calvi_2023] misleading charts should be considered an important feature of data visualisation literacy. A robust 30-item test enables assessment of an individual's ability to accurately comprehend deceptive designs [@ge_calvi_2023]. This work also suggests that attention and critical thinking may benefit viewers in avoiding some, but not all, biased interpretations. Furthermore, using Galesic and Garcia-Retamero's 13-item test [-@galesic_graph_2011], @okan_how_2016 found that higher data visualisation literacy is associated with more time processing a visualisation's misleading features, thus promoting correct interpretations. Lower data visualisation literacy is associated with greater reliance on conventions (e.g., the relationship between vertical position and magnitude).

The empirical work presented in this thesis employs the 5-item version of Garcia-Retamero et al.'s [-@garcia-retamero_measuring_2016] Subjective Graph Literacy scale. Users are asked to rate their competence in working with bar charts, line charts, and pie charts, and also their ability to perform simple tasks using bar charts. The subjective approach echoes prior work in the development of subjective numeracy scales. Despite its short completion time and use of subjective ratings, it is strongly correlated with an *objective* measure of data visualisation literacy [-@galesic_graph_2011]. The scale also produces a final score out of 30, offering greater sensitivity than a similarly brief objective scale, where tallying correct responses produces a final score out of 4 [@okan_using_2019]. These characteristics make for an appropriate tool for assessing participants' data visualisation literacy in experimental studies. Indeed, this measure has been used to assess variability between participants in studies on axis truncation [@yang_truncating_2021], correlation [@strain_effects_2023], information synthesis [@mantri_how_2022], and explanation of visualisations [@yang_explaining_2023].

## Interpreting Absolute Magnitude

Data visualisation design has the potential to impact subjective judgements about many aspects of data, such as variability, noise, and numerosity. Prior research has closely examined how axis truncation can influence judgements of *relative* magnitude (i.e., differences between values). In contrast, little is known about how axis limits may influence judgements of *absolute* magnitude: how large or small values are. Despite this, these judgements can be fundamental in developing a basic interpretation of quantitative data. For example, assessing the probability of rain, the number of patients on a waiting list, the amount of CO2 emitted during a journey, or the level of support for a political candidate, are all judgements of *absolute* magnitude. Limited insight into how magnitude is interpreted in data visualisations impedes understanding of how visualisations may effectively communicate magnitude. **Judging *absolute* magnitude is not an *objective* assessment, but a judgement of values themselves, rather than *relative differences***. Prior research on this topic is summarised below.

In bar charts displaying data on individuals affected by a risk (e.g., @fig-stack-example), perceived likelihood decreases when the total population at risk is emphasised using shaded bars (top), rather than blank space [bottom, @stone_designing_2017]. In bar charts violating the convention of mapping higher values to higher positions, participants frequently misinterpreted absolute magnitudes [@okan_when_2012]. This was due to difficulty in rejecting first impressions, particularly for participants with low data visualisation literacy. However, other work which has combined judgements of values' absolute magnitudes with judgements of relative differences has impeded analysis of the former [@okan_designing_2018]. Researchers have suggested that visualisations which facilitate comprehension of relative differences may fail to effectively communicate the absolute magnitudes of the values depicted, illustrating a potential trade-off in design [@reyna_theory_2008].

```{r}
#| label: fig-stack-example
#| fig-scap: Stimuli used to demonstrate that including additional shaded bars (grey) reduces interpretations of the magnitude of other values (blue), compared to blank space.
#| fig-cap: Stimuli used to demonstrate that including additional shaded bars (grey) decreases interpretations of the magnitude of other values (blue), compared to blank space. Adapted from @stone_designing_2017.
vals1 <- c(0, 6, 7, 10)
vals2 <- c(100, 94, 93, 90)
cats <- c('A', 'B', 'C', 'D') 

mydf <- tibble(vals1, cats)
mydf2 <- tibble(vals1, vals2, cats) %>%
  pivot_longer(cols = vals1:vals2)

stack1 <- mydf2 %>%
  ggplot(aes(x = value, y = cats, fill = name, group = cats)) +
  geom_col(width = 0.5, position = "stack") +
  scale_y_discrete(limits = rev) +
  theme_minimal() +
  coord_cartesian(ylim = c(0.5, 4.5),
                  xlim = c(0, 100),
                  expand = F) +
  labs(x = NULL, y = NULL) +
  theme(panel.border = element_rect(fill = NA),
        panel.grid.major.y = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none") +
  scale_fill_manual(values = c("#4571a8", "#a3a3a3"))

stack2 <- mydf %>%
  ggplot(aes(x = vals1, y = cats)) +
  geom_col(width = 0.5, fill = '#4571a8') +
  scale_y_discrete(limits = rev) +
  theme_minimal() +
  coord_cartesian(ylim = c(0.5, 4.5),
                  xlim = c(0, 100),
                  expand = F) +
  labs(x = NULL, y = NULL) +
  theme(panel.border = element_rect(fill = NA),
        panel.grid.major.y = element_blank(),
        panel.grid.minor = element_blank())

stack1 + stack2 + plot_layout(nrow = 2)
```

One study has specifically focused on how *axis ranges* may inform **subjective** impressions of absolute magnitude. @sandman_high_1994 manipulated the design of risk ladders, where individual probabilities are presented on vertical scales incorporating a range of probability values. Changing this range alters the position of a plotted value. This study found that perceived threat (a composite measure made up of perceived likelihood, danger, reported concern and fear) was higher when the risk appeared near to the top of the ladder, compared to near the bottom. This finding resembles **general** framing effects described in the **data visualisation** literature, wherein interpretations of the same information differ according to the manner in which it is presented **[@verma_designing_2023; @hullman_visualization_2011; an expansion of Tversky and Kahneman's -@tversky_framing_1981 original gain-loss framing effect].** However, the position of plotted values did not completely dictate magnitude judgements. A numerically higher risk plotted at *the same position* near the top of the ladder generated higher ratings. There was also mixed evidence regarding the effects of the axis manipulation on intentions to spend money mitigating the risk. Confidence in the robustness of these findings is limited by various factors including use of a single trial per participant, a single scenario, a composite measure obscuring pure magnitude ratings, and a confounding variable of the risk ladder's range.

Comparing linear and logarithmic risk ladders, @freeman_communicating_2021 did not replicate Sandman et al.'s [-@sandman_high_1994] main finding. However, in addition to a graphical cue to magnitude, they used risk ladders which employed additional symbolic number cues in their titles, labels, and accompanying descriptions (e.g., "12%", "120 out of 1000"). A broken scale may also have reduced the degree to which inferences were based on the value's physical position. Therefore, the *graphical* representation of numbers may have been given less weight in participants' mental representations.

Compared to knowledge on the interpretation of *relative* magnitude in data visualisations, knowledge on the interpretation of *absolute* magnitude is limited. Insufficient research on this topic impedes understanding of the relationship between design choices and subsequent impressions. The cognitive processing of absolute magnitude in data visualisations is the focus of this thesis.

## The Present Thesis

This thesis consists of a detailed investigation into how interpretations of the magnitude of numerical values are influenced by design choices. Three sets of experiments (six experiments in total) each address the overall objective of the thesis: to understand the cognitive processing of absolute magnitude in data visualisations. However, each set of experiments uses a different data visualisation format and investigates a different factor influencing judgements, thus contributing to a comprehensive account of cognitive processing. The following chapter introduces the methodology and epistemological approach employed in this work, prior to the empirical experiments in Chapters 4-6.
