---
title: "Axis Limits and Denominator Information Influence Magnitude Ratings in Bar Charts"
editor: visual

params: 
  eval_models: false
  
format: pdf
    
execute:
  echo: false
  warning: true
  message: true
  include: false
  
bibliography: axis-extension.bib
---

```{r}
#| label: setup
library(tidyverse)
library(lme4)
library(lmerTest)
library(buildmer)
library(qwraps2)
library(emmeans)
library(effectsize)
library(papaja)
library(patchwork)
library(insight)
library(knitr)
library(magick)
library(ggridges)
library(report)
library(MuMIn)
set.seed(45789)
```

```{r}
#| label: lazyload-cache
if (!params$eval_models){
lazyload_cache_dir('axis-extension_cache/html')}
```

```{r}
#| label: wrangle
anon_data1 <- read_csv('data/anon_data1.csv',
                       col_types = cols(.default = "?", genderResp2.text = col_character()))
# correct the coercion of the genderResp2.text to logical

anon_data2 <- read_csv('data/anon_data2.csv')

# perform necessary data wrangling
wrangle <- function(anon_file, .y) {
  # .y captures the index of the file in the list supplied to iwalk

# extract literacy data
# calculate literacy score (sum of five responses)
literacy <- anon_file %>%
  filter(!is.na(q1_slider.response)) %>%
  rowwise() %>%
  mutate(literacy = sum(c(q1_slider.response, 
                          q2_slider.response, 
                          q3_slider.response, 
                          q4_slider.response, 
                          q5_slider.response))) %>%
  select(participant,
         literacy)

# define education categories 
edu_labels <- set_names(c('No formal qualications',
                          'Secondary education (e.g. GED/GCSE)',
                          'High school diploma/A-levels',
                          'Technical/community college',
                          'Undergraduate degree (BA/BSc/other)',
                          'Graduate degree (MA/MSc/MPhil/other)',
                          'Doctorate degree (PhD/other)',
                          'Don\'t know / not applicable'),
                        seq(8,1,-1))

# define gender categories
gender_labels <- set_names(c("Pnts", 
                             "Another",
                             "NB", 
                             "M", 
                             "F"),
                           1:5)
# extract demographics
# link slider response numbers to gender categories 
# link slider response numbers to education categories
demographics <- anon_file %>%
  filter(!is.na(genderResp1.response)) %>%
  mutate(genderResp1.response = 
           recode(genderResp1.response, !!!gender_labels)) %>%
  mutate(edu_slider.response =
           recode(edu_slider.response, !!!edu_labels)) %>%
  select(participant,
         ageResp.text,
         genderResp1.response,
         edu_slider.response)

# extract duration data (in seconds)
durations <- anon_file %>%
  filter(!is.na(total_duration)) %>%
  select(participant, total_duration)
  
# select relevant columns
# select only experimental items
# add literacy and demographic data
# change data types where appropriate
# output this file with suffix 'tidy'
anon_file %>% 
  filter(item_type == "E") %>%
  select(matches(c("participant",
                   "item_no",
                   "item_type",
                   "cond",
                   "axis",
                   "denominator",
                   "slider.response",
                   "mag_slider.response",
                   "con_slider.response",
                   "seed_no"))) %>% 
    inner_join(literacy, by = "participant") %>%
    inner_join(demographics, by = "participant") %>%
    inner_join(durations, by = "participant") %>%
    mutate(total_duration = total_duration / 60) %>%
    mutate(across(matches(c("cond", "axis")), 
                  ~ case_match(.x,
                               "full" ~ "extend",
                               "trunc" ~ "default"))) %>%
    mutate(across(matches(c("axis", "denominator", "cond")), as_factor)) %>%
    mutate(across(c("participant", "item_no"), as.character)) %>%
    assign(paste0("e", .y),
           value = ., envir = .GlobalEnv)
}

iwalk(list(anon_data1, anon_data2), wrangle)


# set sum contrasts
contrasts(e2$axis) <- contr.sum(2)
contrasts(e2$denominator) <- contr.sum(2)
```

```{r}
#| label: anova-results-function
# this function takes two nested models, runs an anova, and the outputs the Likelihood Ratio Statistic, degrees of freedom, and p value to the global environment
anova_results <- function(test_model, full_model) {
  
  # first argument 
  test_model_name <- deparse(substitute(test_model))
  full_model_name <- deparse(substitute(full_model))

  if (class(test_model) == "buildmer") test_model <- test_model@model
  if (class(full_model) == "buildmer") full_model <- full_model@model
  
  anova_output <- anova(test_model, full_model)
  
  assign(paste0(test_model_name, ".Chi"),
         anova_output$Chisq[2],
         envir = .GlobalEnv)
  assign(paste0(test_model_name, ".Df"),
         anova_output$Df[2],
         envir = .GlobalEnv)
  assign(paste0(test_model_name, ".p"),
         anova_output$`Pr(>Chisq)`[2],
         envir = .GlobalEnv)
  
  es <- eta_squared(anova(full_model), partial = TRUE) 
  
  es %>% pull(Parameter) %>%
    map(function(x) assign(paste0(model_name, 
                                  ".eta.", 
                                  str_replace(x, ":", "_")),
                           es %>%
                             filter(Parameter == x) %>% 
                             pull(Eta2_partial),
                           envir = .GlobalEnv))
}
```

```{r}
#| label: summary-extract-function
# this function extracts test statistics and p values from model summaries
summary_extract <- function(model) {
  
  model_name <- deparse(substitute(model))
  
  if (class(model) == "buildmer") model <- model@model
  
  es <- eta_squared(anova(model), partial = TRUE) 

  model %>% 
    anova() %>%
    as_tibble(rownames = "term", 
              .name_repair = make.names) %>%
    rename("p" = "Pr..F.") %>%
    inner_join(es, by = join_by("term" == "Parameter")) %>%
    mutate(term = str_replace_all(term, ":", "_")) %>%
    group_split(term) %>%
    map(~ {
      vals <- as.list(.x)
      names(vals) <- paste0(model_name, 
                            "_", 
                            .x$term, 
                            "_", 
                            names(vals))
      list2env(vals, envir = globalenv())
    })
  
}
```

```{r}
#| label: get-contrasts-function

get_contrasts <- function(contrast_df, condition) {

  df_name <- deparse(substitute(contrast_df))

  contrast_df %>% 
    contrast("consec", 
             simple = "each", 
             combine = TRUE, 
             adjust = "sidak") %>%
    as_tibble() %>% 
    filter(!!sym(condition) != ".") %>%
    group_split(!!sym(condition)) %>%
    map(~ {
      vals <- as.list(.x)
      names(vals) <- paste0(df_name, 
                            "_",
                            pull(., {{condition}}),
                            "_", 
                            names(vals))
      list2env(vals, envir = globalenv())
    })
  
}
```

```{r}
#| label: get-anomalies-function

# returns the proportion of datasets which needed to re-generated for the highest data point to exceed the highest gridline

get_anomalies <- function(dataset){
  dataset %>%
  pull(seed_no) %>% # extract column with seed numbers
  unique() %>% # get unique values
  na.omit() %>% # omit NAs
  sort() %>% # ascending order (since they were generated in order)
  diff() %>% # calculate difference between each pair of values
  # the while loop was entered on every trial including the first
  # the first seed value in both experiments is 2
  # this indicates that a new seed number was not selected for the first chart
  #c(1, .) %>% # therefore we prepend a 1 to indicate this
  `>`(1) %>% # count the number of cases where a new seed number was selected
  mean()*100 # calculate the proportion of TRUE cases as a %
}
```

```{r}
#| label: print-es-function
# for dealing with effect sizes less than .001
print_es <- function(x) {ifelse(x<.01, "< .01", paste("=", printnum(x)))}
```

```{r}
#| label: print-formula
# Unfortunately, simplify.formula() ignores the common ordering for mixed effects models where fixed effects come first and random effects afterwards.
# This is solved by simplifying the fixed and random effects separately, then combining them.

print_formula <- function(model){

# simplify fixed effects only 
fixfx <- formula(model) %>% 
  nobars() %>%
  simplify.formula()

# simplify random effects only
ranfx <- formula(model) %>% 
  getrandom() %>%
  simplify.formula()

# combine fixed and random effects
# convert formula to a string in order to replace terms
# and add brackets to random effects
# then convert back to a formula
  merge.formula(fixfx, ranfx) %>%
  format_formula() %>%
  str_replace_all(c("mag_slider.response" = "magnitude", 
                      "con_slider.response" = "confidence",
                      "slider.response" = "magnitude", 
                      "axis" = "axis_limit",
                      "cond" = "axis_limit", 
                    '1' = '(1',
                  '(participant|item_no)' =  '\\1)',
                  'formula: ' = ''))
}

getrandom <- function(form) {
    
    parens <- function(x) {paste0("(",x,")")}
    onlyBars <- function(form) {
      reformulate(
        sapply(
          findbars(form), # list of character vector for each random effect
          function(x)  parens(deparse(x))), # put each character vector in brackets
        response = form[[2]]) 
    }
    
    out <- onlyBars(form)
    return(out)
}

merge.formula <- function(form1, form2, ...){
    # adapted from https://stevencarlislewalker.wordpress.com/2012/08/06/merging-combining-adding-together-two-formula-objects-in-r/
    
    # get character strings of the names for the responses 
    # (i.e. left hand sides, lhs)
    lhs1 <- deparse(form1[[2]])
    #print(lhs1)
    lhs2 <- deparse(form2[[2]])
    #print(lhs2)
    if(lhs1 != lhs2) stop('both formulas must have the same response')
    
    # get character strings of the right hand sides
    rhs1 <- strsplit(paste(form1[3]), " \\+ ")[[1]] 
    rhs2 <- strsplit(paste(form2[3]), " \\+ ")[[1]] 
    
    # put the two sides together with the amazing 
    # reformulate function
    out <- reformulate(termlabels = c(rhs1, rhs2), 
                       response = lhs1)
    
    # set the environment of the formula (i.e. where should
    # R look for variables when data aren't specified?)
    #environment(out) <- parent.frame()
    return(out)
  }
```

```{r}
#| label: gender-proportions
gender_e1 <- e1 %>%
    distinct(participant, .keep_all = TRUE) %>% 
    group_by(genderResp1.response) %>% summarise(cnt = n()) %>%
    reframe(freq = cnt / sum(cnt) *100, 
            gender = unique(genderResp1.response)) %>%
  pivot_wider(names_from = gender, values_from = freq)

gender_e2 <- e2 %>%
    distinct(participant, .keep_all = TRUE) %>% 
    group_by(genderResp1.response) %>% summarise(cnt = n()) %>%
    reframe(freq = cnt / sum(cnt) *100, 
            gender = unique(genderResp1.response)) %>%
  pivot_wider(names_from = gender, values_from = freq)
```

## Placeholder

## Abstract

Consider a statistic corresponding to the number of public transport users in a particular town. Gauging whether this number is large or small requires awareness of the total population (the denominator). In data visualisations, an axis extended beyond plotted values can act as a graphical cue to a denominator value, but default axis upper limits (e.g., in ggplot2) are typically based on the highest plotted value. In two experiments (combined *N* = 350), we explore the influence of default and extended axes on interpretations of the magnitude in bar charts. We also investigate the influence of accompanying denominator information on participants' assessments. We observe that values plotted using default axes were rated as higher, compared to values plotted using extended axes. The absence of denominator information amplifies the effect of axis limits on judgements. This demonstrates that axes which incorporate denominator values influence interpretations of presented data. Whereas prior work has often focused on judgements of the *differences between values*, this work contributes to an understanding of how the magnitudes of *the values themselves* are interpreted by viewers. We also discuss implications for effective design, which involve considering both axis limits and accompanying contextual information.

## Introduction

The question 'Is it a big number?' is often raised on the BBC radio programme *More or Less* when probing eye-catching statistics. A figure of several million pounds may initially seem large, but may represent a small proportion of total government spending. Awareness of a denominator value can influence judgement of a number's magnitude. In data visualisation, this contextual information can be displayed by extending an axis to accommodate the denominator value. However, this approach is infrequently used, since typical default axis settings are based on plotted data only. In this study, we investigate how these axis limits affect interpretations of how large or small plotted values are.

### Overview

Across two experiments, we investigate the interpretation of magnitudes in bar charts. We plotted fictitious datasets which contained multiple observations, all with the same denominator values. In the first experiment, we displayed charts with default axes which terminated just above plotted values, or axes which extended to the denominator value specified in accompanying text. Participants rated values' magnitudes as higher when default axes were used, compared to extended axes. In the second experiment, we manipulated the axis limits, as before, and also the presence of the denominator information in accompanying text. Variation in responses to the two difference axis settings was starker when denominator information was not supplied. This indicates that this information influences the biasing effect of a chart's appearance.

### Related Work

A wealth of research demonstrates biases in the interpretation of numbers. A survival rate elicits different judgements of a disease compared to its corresponding mortality rate [@tversky_framing_1981], the fat content of a meat product elicits different judgements of the product compared to its corresponding lean content [@levin_associative_1987]. The units used to express the same values (e.g., months vs. years) affect comparisons [@burson_six_2009; @monga_years_2012] and also interpretations of precision and accuracy [@zhang_how_2012].

Various biases in magnitude judgements reveal the importance of accounting for numerical context. Base rate neglect describes difficulty acknowledging population-level characteristics when making judgements about a sample [@cosmides_are_1996]. Format neglect describes a bias against incorporating set size information when judging percentage formats (top 20%) and numerical formats (top 10, [@sevilla_format_2018]). Denominator neglect occurs in judgements which overweight numerator information at the expense of denominator information [@reyna_numeracy_2008]. The latter also leads (in part) to large percentages of a small number appearing greater than the *numerically equivalent* smaller percentages of a larger number [@li_big_2013]. The general mechanism responsible for these biases is a failure to properly acknowledge numerical context.

Visualisations can help combat biases. Denominator information becomes visually available when icon arrays present both focal outcomes (e.g., number deceased) *and also* alternative outcomes (e.g., number survived). Research suggests that the combined array acts as a visual cue to the denominator (e.g., total number at risk), facilitating reasoning. For example, including alternative outcomes in an icon array, and therefore displaying denominator information, reduces denominator neglect, increasing comprehension of relative risk [@garcia-retamero_who_2010]. Icon arrays displaying both types of outcome are particularly helpful for understanding datasets with unequal denominators, and for individuals with high graph literacy [@okan_individual_2012]. However, these effects are largest when depicting small probabilities [@okan_probability_2020].

Stacked bar charts function similarly to icon arrays: lower bars represent the focal outcome, upper bar represent the alternative outcome, and their combination represents the denominator. Like icon arrays, stacked bar charts lessen the influence of denominator neglect [@stone_foregroundbackground_2003]. However, denominator information can be displayed in bar charts without using additional stacked bars representing alternative outcomes. Extending an axis to incorporate the denominator value also communicates relevant numerical context. In this case, the blank space between the bars for focal outcomes and the upper axis limit corresponds to the alternative outcomes. Research has demonstrated that bar charts representing alternative outcomes using blank space increase perceptions of risk likelihood compared to those representing alternative outcomes using stacked bars [@stone_designing_2017]. This research did not examine how presenting *denominator information* influences interpretation, since identical axis limits were employed across conditions.

Directly manipulating bar charts' upper axis limits provides insight into use of this source of denominator information. Bar charts with axes which extended to the denominator value produce more accurate estimates of changes in risk [@garcia-retamero_who_2010]. This design also elicits decreased ratings of risk perception [@okan_designing_2018], though numerical labels reduce this effect. In both studies, accompanying text included the denominator value. These studies demonstrate that extending axes to incorporate denominator values influences interpretation of risk. However, they do not provide specific evidence on how interpretations of *plotted values' magnitudes* are affected. @garcia-retamero_who_2010 measured risk understanding: how faithfully participants represented the exact numbers displayed. Only assessing comprehension fails to capture individuals' *impressions* of plotted information [@feldman-stewart_further_2007]. Understanding the 'gist' obtained from a visualisation is crucial since this takes precedence over 'verbatim' information when making decisions [@reyna_theory_2008]. @reyna_theory_2008 argues that assessing gist requires consideration of how plotted values' magnitudes are interpreted, since plotted values' relative differences are only one aspect of a dataset conveyed by a visualisation. Indeed, @okan_designing_2018 collected magnitude ratings, yet these cannot be examined in isolation, since they were assimilated into a combined measure of perceived risk, along with ratings of the degree of *difference between* plotted values. Outside the risk communication literature, a substantial body of research has demonstrated that judgements of the difference between values change as a function of axis range [@pandey_how_2015; @witt_graph_2019; @correll_truncating_2020; @yang_truncating_2021]. In spite of this, research has neglected the effects of axis range on judgements of the magnitude of *the values themselves*. This is the focus of experiments presented in this work.

Various accounts have sought to explain the consequences of including denominator information in visualisations. Depicting denominators may facilitate understanding of part-to-whole relationships, diminishing class-inclusion errors associated with denominator neglect [@reyna_theory_2008]. This argument is consistent with Fuzzy Trace Theory, which also predicts the influence of physical attributes in gist representations, such that the appearance of short bars in charts with extended axes may contribute to smaller magnitude judgements [@reyna_theory_2008]. Additionally, [@stone_salience_2018] suggest facilitation of proportional reasoning may be largely responsible for observed effects. Increasing the salience of the denominator in text fails to affect judgements, yet a graphical representation effectively communicates the true scale of the denominator, helping put numerators into perspective.

Prior work on extending axes, discussed above, did not disclose methods for determining axis limits in charts without denominators. The values used as upper limits appear to be arbitrary. In the present study, we increase ecological validity by employing default axis limits from {ggplot2} [@wickham_ggplot2_2016], a popular visualisation tool used in the R programming environment. Furthermore, previous studies' statistical power and generalisability have been limited by the use of one [@okan_designing_2018] or two [@garcia-retamero_who_2010] trials per participant. Our experiments explore a range of scenarios (32 experimental trials per participant). The data presented are also unrelated to risk judgements, the domain of this prior work.

### Open Research Statement

Data, analysis code, and pre-registrations are available at osf.io/854uc/.

## Experiment 1

### Introduction

This experiment investigates the influence of axis limits on interpretations of plotted values' magnitude. Participants viewed bar charts with default axes, or axes which extended to a denominator value well above the bars. Comparing participants' interpretations captures the influence of displaying the same data with and without numerical context.

### Method

#### Materials

We developed 40 scenarios about fictitious studies. Each study evaluated a specific outcome across five categories (e.g., the number of items produced without defects, for five manufacturing methods). The denominator (e.g., total number of items produced) was identical for each category.

We generated bar charts in R [@r_core_team_r_2022] using {ggplot2} (version 4.1.2), {tidyverse} (version 1.3.1) and {ggh4x} (version 0.2.1). The two versions of each chart displayed the same five values, but employed different y-axis limits. Denominator values (400, 500, or 600) were used to generate datasets: data were sampled from normal distribution with a mean equal to either 20% or 40% of a given denominator value, and a standard deviation equal to 1% of the denominator value.

For charts with extended axes, the denominator value was used as the y-axis upper limit. The other charts used a y-axis upper limit which was dictated by ggplot2's default axis settings. These settings automatically identify a set of convenient breaks for each dataset, then slightly extend the plot area, adding an additional 5% of the axis range. In both conditions, a smaller expansion factor of 1% was applied to the lower axis limit, in order to eliminate visible space below the 0 baseline. @fig-example-charts shows example charts for both conditions.

```{r}
#| label: fig-example-charts
#| include: true
#| out-width: "500px"
#| fig-scap: Example charts for Experiment 1.
#| fig-cap: "Example charts for Experiment 1. The same data appears in both charts. Accompanying text explained what the values represented: _'The graph shows, for each manufacturing method, how many of the items were free from defects'_. The chart with the default axes (left) employs an upper limit determined by ggplot2. The chart with the extended axes (right) employs an upper limit equal to the dataset's denominator value."
img1 <- image_read("images/E14trunc.png")
img2 <- image_read("images/E14full.png")
image_append(c(img1, img2))
```

For the majority of datasets generated, the default settings produced charts where the highest gridline did not exceed the tallest bar. For consistency, when the opposite situation occurred, we used a different random seed to generate an alternative dataset for both conditions. `r printnum(get_anomalies(e1), digits = 0)`% of datasets used were generated using this method.

In experimental trials (32 total), plotted values consisted of relatively small proportions of the dataset's denominator value (roughly 20% or 40%). To introduce variety and encourage attention, eight filler trials showed plotted values which were roughly 90% of the corresponding denominator value. Denominators for filler trials were selected so that numerical labels on the y-axis would approximately resemble either extended or default bar charts from experimental trials.

We included six attention check trials to assess participants' engagement with the task. These trials were similar to experimental and filler trials, consisting of text, a bar chart, a question and a visual analogue scale. However, participants were instructed to ignore the bar chart and provide a specified response on the visual analogue scale.

#### Design

We employed a within-participants design: participants viewed 16 different charts in each of the two conditions (32 experimental trials total). The correspondence between scenarios and conditions was counterbalanced using two lists. However, all participants saw the same versions of the eight filler items and six attention check items. There were a total of 46 trials, which were presented in a random order.

#### Participants

Participants were recruited using Prolific.co. The experiment was advertised to fluent English speakers with normal-or-corrected to normal vision, who had previously participated in at least 100 studies on the site.

Data were returned by 157 participants. Per pre-registered exclusion criteria, seven participants' submissions were rejected because they answered more than one of six attention check questions incorrectly. Participants whose submissions were accepted received £3.50.

The final sample consisted of 150 participants (`r printnum(gender_e1$M)`% male, `r printnum(gender_e1$F)`% female, `r printnum(gender_e1$NB)`% non-binary). Mean age was `r printnum(e1 %>% pull(ageResp.text) %>% mean())` years (*SD* = `r printnum(e1 %>% pull(ageResp.text) %>% sd())`). The mean data visualisation literacy score was `r printnum(e1 %>% pull(literacy) %>% mean())` (*SD* = `r printnum(e1 %>% pull(literacy) %>% sd())`), out of a maximum of 30.

This experiment was approved by the University of Manchester's Division of Neuroscience and Experimental Psychology Ethics Committee (ethics code: 2022-11115-24245).

#### Procedure

We programmed the experiment using PsychoPy (version 2022.1.4, [@peirce_psychopy2_2019]). Participants were instructed to carry out the experiment using a laptop or desktop computer (not a mobile phone or tablet). After providing informed consent, participants completed a demographic questionnaire and Garcia-Retamero et al.'s [@garcia-retamero_measuring_2016] five-item subjective data visualisation literacy scale.

Participants were asked to imagine they were a researcher tasked with determining the outcome of experiments and surveys. They were instructed to make an overall assessment of all data presented in a graph after studying the text, graph, and question. All questions asked about plotted values' magnitudes (e.g., 'How successful were the manufacturing methods?'), with participants responding on visual analogue scales with anchors at the extremes (e.g., 'very unsuccessful', 'very successful'). @fig-e1-trial shows an example trial.

```{r}
#| label: fig-e1-trial
#| include: true
#| out-width: "500px"
#| fig-scap: An example trial from Experiment 1, showing a bar chart with a default axis limit. 
#| fig-cap: An example trial from Experiment 1, showing a bar chart with a default axis limit. 
include_graphics("images/trial_e1.png")
```

Participants were permitted to move the response marker as many times as they liked before proceeding to the next trial, but could not return to previous trials. The response scale's granularity was altered for each attention check item, such that participants could only respond at the extremes or the middle of the scale. Finally, participants were informed that all data presented was fictitious and were given the option to provide comments on the experiment and describe any strategies used. Average completion time was `r printnum(e1 %>% pull(total_duration) %>% mean(), digits = 1)` minutes.

### Analysis

We conducted analysis using R [@r_core_team_r_2022] (version 4.2.1). Linear mixed models were built using {lme4} [@bates_fitting_2015]. Each model was based on a maximal model with by-participant and by-item random effects [@barr_random_2013], and {buildmer} [@voeten_buildmer_2022] was used to identify the final random effects structure, ensuring convergence and removing terms not significantly contributing to explaining variance.

#### Magnitude Ratings

@fig-e1-mag shows the distribution of ratings for charts with default axes and extended axes.

```{r}
#| label: fig-e1-mag
#| include: true
#| message: false
#| out-width: "500px"
#| fig-scap: The distribution of visual analogue scale ratings in response to default and extended axis limits. 
#| fig-cap: The distribution of visual analogue scale ratings in response to default and extended axis limits. Each circle represents a participant's response to an individual bar chart.
e1 %>%
  ggplot(aes(x = slider.response, 
             y = cond)) +
  geom_density_ridges(scale = 0,
                      colour = "lightgrey",
                      alpha = 0,
                      jittered_points = T,
                      position = position_raincloud(height = 0.3),
                      point_alpha = 0.05,
                      point_colour = "black",
                      point_size = 0.75) +
  geom_density_ridges(aes(height = after_stat(density)),
                      stat = "density",
                      scale = 0.5,
                      colour = "black",
                      fill = "darkgrey",
                      panel_scaling = FALSE) +
  geom_boxplot(outlier.shape=NA,
               width = 0.10,
               colour = "white",
               fill = "white",
               alpha = 0,
               lwd = 1,
               position = position_nudge(y=-.2)) +
  geom_boxplot(outlier.shape=NA,
               width = 0.09,
               colour = "black",
               fill = "white",
               alpha = 0.7,
               lwd = 0.5,
               position = position_nudge(y=-.2)) +
  scale_y_discrete(limits = c("extend", "default"),
                   labels = c("Extended\nAxis Limit", "Default\nAxis Limit")) + 
  labs(title = "Experiment 1 - Distribution of Magnitude Ratings",
       subtitle =  "Density Plots, Boxplots, and Raw Data",
       y = NULL,
       x = NULL) + 
  scale_x_continuous(labels = c('Very low\nmagnitude', 'Very high\nmagnitude'),
                     breaks = c(1,2),
                     minor_breaks = c()) +
  theme_minimal(base_size = 10) +
  theme(aspect.ratio = 0.6)
```

```{r}
#| label: e1-mag
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e1_mag <- buildmer(slider.response ~ cond +
                     (1 + cond | participant) + 
                     (1 + cond | item_no),
                   data = e1)
```

```{r}
summary_extract(e1_mag)
```

Linear mixed-effects modelling revealed that participants awarded higher ratings to charts with default axes, compared to charts with extended axes: F(`r printnum(e1_mag_cond_NumDF)`, `r printnum(e1_mag_cond_DenDF)`) = `r printnum(e1_mag_cond_F.value)`, p `r printp(e1_mag_cond_p, add_equals = T)`, partial $\eta^2$ = `r printnum(e1_mag_cond_Eta2_partial)`.

This model employed a maximal random effects structure, capturing the baseline responses (intercepts) and differences between the two axis settings (slopes) separately for each individual participant and each individual item. The model formula was as follows: `` `paste(print_formula(e1_mag))` ``

#### Magnitude Ratings and Data Visualisation Literacy

```{r}
#| label: e1-lit
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e1_mag_l <- lmer(add.terms(formula(e1_mag),
"literacy"),
              data = e1)
```

```{r}
#| label: e1-lint
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e1_mag_lint <- buildmer(slider.response ~ cond*literacy +
                     (1 + cond | participant) + 
                     (1 + cond*literacy | item_no),
                     buildmerControl=list(                         include='slider.response ~ cond*literacy'),
                   data = e1)

emtrends(e1_mag_lint@model, pairwise ~ cond, var = "literacy")

emmip(e1_mag_lint@model, cond ~ literacy, cov.reduce = range) 
```

```{r}
#| label: e1-mag-statistics
# extract test statistics
summary_extract(e1_mag_l)
summary_extract(e1_mag_lint)

emtrends(e1_mag_lint@model, "cond", var = "literacy") %>% 
  as_tibble() %>% 
  group_split(cond) %>% map(~ {
    vals <- as.list(.x)
    names(vals) <- paste0("e1_mag_lint", 
                          "_", 
                          .x$cond, 
                          "_", 
                          names(vals))
    list2env(vals, envir = globalenv())
})
```

Accounting for differences in data visualisation literacy did not change the significant effect of axis limits: F(`r printnum(e1_mag_l_cond_NumDF)`, `r printnum(e1_mag_l_cond_DenDF)`) = `r printnum(e1_mag_l_cond_F.value)`, p `r printp(e1_mag_l_cond_p, add_equals = T)`, partial $\eta^2$ `r print_es(e1_mag_l_cond_Eta2_partial)`.

However, there was an interaction between data visualisation literacy and axis limits: F(`r printnum(e1_mag_lint_cond_literacy_NumDF)`, `r printnum(e1_mag_lint_cond_literacy_DenDF)`) = `r printnum(e1_mag_lint_cond_literacy_F.value)`, p `r printp(e1_mag_lint_cond_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e1_mag_lint_cond_literacy_Eta2_partial)`. A one unit increase in data visualisation literacy reduced magnitude ratings for default charts by `r printnum(abs(e1_mag_lint_default_literacy.trend))`, but reduced magnitude ratings for extended charts by `r printnum(abs(e1_mag_lint_extend_literacy.trend))`.

```{r}
#| label: fig-e1-mag-lint
#| out-width: "500px"
#| include: true
#| warning: false
my_palette <- unname(palette.colors(palette = "Okabe-Ito")[2:3])

emmip(e1_mag_lint@model, cond ~ literacy, cov.reduce = range,
      linearg = list(linetype = "solid", lwd = 1.5)) +
  scale_color_manual(limits = c('default', 'extend'), 
                       labels = c('Default', 'Extended'),
                   values = my_palette) +
  scale_y_continuous(limits = c(1,2), 
                     breaks = c(1,2), 
                     minor_breaks = seq(1,2,0.2),
                     labels = c('Very low\nmagnitude', 
                                'Very high\nmagnitude')) + 
  labs(color = "Axis Limit",
       y = "Magnitude Rating",
       x = "Data Visualisation Literacy",
       title = "Experiment 1 - Data Visualisation Literacy Interaction",
       subtitle =  "Estimated Marginal Means") + 
  theme_minimal(base_size = 10)
```

### Discussion

This experiment explored the consequences of including a graphical cue to a denominator value using bar charts' axes. We observed that plotted values' magnitudes were interpreted as smaller when a default axis limit was used, compared to an axis limit equal to the dataset's denominator value. Therefore, assessments of data were biased by the presence or absence of numerical context in bar charts.

Denominator information informs magnitude judgements. In bar charts with extended axes, denominator information was available through the accompanying text and through axes. Comparison with bar charts employing default axes, where denominator information was *only* available through text, reveals the contribution of the graphical cue to the denominator value. Inconsistency in the differences between conditions illustrates variation in interpretation. The relative similarity of lower magnitude ratings across conditions indicates some attention to denominator information in the absence of a graphical cue. However, some extreme high magnitude ratings suggest that the appearance of tall bars carried the implication of large values. These ratings may indicate a failure to account for denominator information in the absence of a graphical cue. We investigate the role of denominator information further in Experiment 2.

## Experiment 2

### Introduction

Experiment 1 found differences in interpretations of data presented using different axes limits. Overall, plotted data were associated with lower magnitudes when presenting using axes which extended to a denominator value. Compared to bar charts with extended axes, charts with no graphical cue to a denominator value elicited a wider variety of responses. This variety appears to reflect differences in how the denominator information supplied in accompanying text is used in magnitude judgements. This raises questions about how text, including denominator information, might influence the interpretation of different chart designs.

By manipulating the presence of denominator information in accompanying text, in addition to manipulating axis limits, we investigate how these textual and graphical cues inform assessments of data. This allows us to understand how different chart designs are interpreted with and without additional numerical context. This 2x2 design also allows us to determine whether we can replicate the findings from Experiment 1 and also gives us the opportunity to explore whether ratings in the absence of denominator information correspond to the previously observed pattern of extreme ratings.

This second experiment requires minor adaptations to materials and procedure. First, there is a risk that highly ambiguous trials without denominator information supplied in text will elicit unreliable random ratings. Therefore, we collect additional confidence ratings to directly index this aspect of participants' evaluations. This provides a more comprehensive view of participants' cognitive states and interpretations. Second, when denominators are not supplied in text, participants may use denominator values supplied in previous trials to inform their judgements. A limited range of denominators (as in Experiment 1) would artificially diminish uncertainty regarding possible values, inhibiting authentic, spontaneous judgements. Therefore, we expand the range of denominator values in Experiment 2. Third, increasing the number of fillers (which depict relatively high magnitudes) to match the number of experimental items (which depict relatively low magnitudes) will avoid priming effects by ensuring high and low magnitudes seem equally plausible.

### Method

#### Materials

We generated bar charts in R using {ggplot2} (version 4.2.1), {tidyverse} (version 1.3.2) and {ggh4x} (version 0.2.3).

Bar charts were generated using the same method as in Experiment 1. We used the same scenarios from Experiment 1, and generated 24 new scenarios for use as additional filler items, thus employing 32 experimental items and 32 filler items. To increase variation across datasets, we employed a wider range of denominators (200, 400, 600, and 800) meaning the plotted values differed from Experiment 1.

We added the word 'surveyed' or 'assessed' to the accompanying text for seven items where the absence of a denominator may have implied that data were collected for the entire population under study. For example, where the study concerned data collected in five towns, the final sentence read 'The graph shows, for each town, how many people *surveyed* used public transport regularly', to avoid the implication that the denominator was equal to an entire town's population. This ensured that the inclusion of denominator values was equally informative across all scenarios.

`r printnum(get_anomalies(e2), digits = 0)`% of datasets used were re-generated to ensure that the highest gridline of a default axis did not exceed the highest plotted value.

#### Design

We employed a within-participants 2x2 Latin-squared design with two factors: axis limits (default vs. extended) and denominator information (present vs. absent). Participants viewed 8 different charts for each combination of conditions (32 experimental trials total). The correspondence between scenarios and conditions was counterbalanced using four lists. However, all participants saw the same versions of the 32 filler items and six attention check items.

#### Participants

Participants were recruited using Prolific.co, using the same inclusion criteria as Experiment 1. Additionally, the experiment was not advertised to individuals who completed Experiment 1.

Data were returned by 208 participants. Per pre-registered exclusion criteria, eight participants' submissions were rejected because they answered more than one of six attention check questions incorrectly. Participants whose submissions were accepted received £5.00.

The final sample consisted of 200 participants (`r printnum(gender_e2$M)`% male, `r printnum(gender_e2$F)`% female, `r printnum(gender_e2$NB)`% non-binary, `r printnum(gender_e2$Another)`% other, `r printnum(gender_e2$Pnts)`% prefer not to say). Mean age was `r printnum(e2 %>% pull(ageResp.text) %>% mean(na.rm = T))` years (*SD* = `r printnum(e2 %>% pull(ageResp.text) %>% sd(na.rm = T))`)[^1]. The mean data visualisation literacy score was `r printnum(e2 %>% pull(literacy) %>% mean())` (*SD* = `r printnum(e2 %>% pull(literacy) %>% sd())`), out of a maximum of 30.

[^1]: Age data were unavailable for `r e2 %>% distinct(participant, .keep_all = TRUE) %>% pull(ageResp.text) %>% is.na() %>% sum()` participants

This experiment was approved by the University of Manchester's Division of Neuroscience and Experimental Psychology Ethics Committee (ethics code: 2023-11115-28428).

#### Procedure

The procedure was identical to Experiment 1, except for the addition of a confidence rating, where participants were asked 'How confident are you in your response?'. The anchors on the response scale were 'Not very confident' and 'Very confident'. @fig-e2-trial shows an example trial.

For attention check items, participants were asked to provide a specific response on the magnitude rating scale, and a random response on the confidence rating scale.

Average completion time was `r printnum(e2 %>% pull(total_duration) %>% mean(), digits = 1)` minutes.

```{r}
#| label: fig-e2-trial
#| include: true
#| out-width: "500px"
#| fig-scap: An example trial from Experiment 2, showing a bar chart with an extended axis limit.
#| fig-cap: An example trial from Experiment 2, showing a bar chart with an extended axis limit. Note the presence of an additional confidence rating scale.

include_graphics("images/trial_e2.png")
```

### Analysis

#### Magnitude Ratings

@fig-e2-mag shows the distribution of magnitude ratings for charts with default axes and extended axes, where denominators were absent from text, and where they were present.

```{r}
#| label: fig-e2-mag
#| include: true
#| message: false
#| out-width: "500px"
#| fig-asp: 1
#| fig-scap: The distribution of visual analogue scale ratings in response to default and extended axis limits, shown separately for trials where denominator values were absent from accompanying text, and trials where denominator values were present in accompanying text.
#| fig-cap: The distribution of visual analogue scale ratings in response to default and extended axis limits, shown separately for trials where denominator values were absent from accompanying text (top), and trials where denominator values were present in accompanying text (bottom). Each circle represents a participant's response to an individual bar chart.

denom_labs <- c("Denominator Present in Text", 
                 "Denominator Absent from Text")
names(denom_labs) <- c("pres", "abs")

e2 %>%
  ggplot(aes(x = mag_slider.response, 
             y = axis)) +
  geom_density_ridges(scale = 0,
                      colour = "lightgrey",
                      alpha = 0,
                      jittered_points = T,
                      position = position_raincloud(height = 0.3),
                      point_alpha = 0.05,
                      point_colour = "black",
                      point_size = 0.75) +
  geom_density_ridges(aes(height = after_stat(density)),
                      stat = "density",
                      scale = 0.5,
                      colour = "black",
                      fill = "darkgrey",
                      panel_scaling = FALSE) +
  geom_boxplot(outlier.shape=NA,
             width = 0.10,
             colour = "white",
             fill = "white",
             alpha = 0,
             lwd = 1,
             position = position_nudge(y=-.2)) +
  geom_boxplot(outlier.shape=NA,
               width = 0.09,
               colour = "black",
               fill = "white",
               alpha = 0.7,
               lwd = 0.5,
               position = position_nudge(y=-.2)) +
  scale_y_discrete(limits = c("extend", "default"),
                   labels = c("Extended\nAxis Limit", "Default\nAxis Limit")) + 
  labs(title = "Experiment 2 - Distribution of Magnitude Ratings",
       subtitle =  "Density Plots, Boxplots, and Raw Data",
       y = NULL,
       x = NULL) + 
  scale_x_continuous(labels = c('Very low\nmagnitude', 'Very high\nmagnitude'),
                     breaks = c(1,2),
                     minor_breaks = c()) + 
  facet_wrap(vars(denominator), ncol = 1, labeller = labeller(denominator = denom_labs)) +
  theme_minimal(base_size = 10) +
  theme(aspect.ratio = 0.6)
```

```{r}
#| label: e2-mag
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_mag <- buildmer(mag_slider.response ~ axis*denominator +
                     (1 + axis*denominator | participant) + 
                     (1 + axis*denominator | item_no),
                   data = e2)
```

```{r}
summary_extract(e2_mag)
```

A mixed effects model revealed that charts with default axes elicited higher ratings compared to charts with extended axes (F(`r printnum(e2_mag_axis_NumDF)`, `r printnum(e2_mag_axis_DenDF)`) = `r printnum(e2_mag_axis_F.value)`, p `r printp(e2_mag_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_axis_Eta2_partial)`) and charts not accompanied by a denominator in text elicited higher ratings than those accompanied by a denominator (F(`r printnum(e2_mag_denominator_NumDF)`, `r printnum(e2_mag_denominator_DenDF)`) = `r printnum(e2_mag_denominator_F.value)`, p `r printp(e2_mag_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_denominator_Eta2_partial)`).

Crucially, there was also a significant interaction between axis limits and denominator information: F(`r printnum(e2_mag_axis_denominator_NumDF)`, `r printnum(e2_mag_axis_denominator_DenDF)`) = `r printnum(e2_mag_axis_denominator_F.value)`, p `r printp(e2_mag_axis_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_axis_denominator_Eta2_partial)`. @fig-e2-mag-int plots this interaction.

```{r}
#| label: e2-mag-contrasts

e2_mag_emm <- emmeans(e2_mag@model, pairwise ~ axis * denominator, adjust = 'sidak') 
  
get_contrasts(e2_mag_emm, condition = "denominator")
```

Pairwise comparisons produced using {emmeans} [@lenth_emmeans_2021] revealed that charts with extended and default axes were rated differently when the denominator was present, replicating the effect from Experiment 1 (z = `r printnum(e2_mag_emm_pres_z.ratio)`, p `r printp(e2_mag_emm_pres_p.value, add_equals = TRUE)`), and also when the denominator was absent (z = `r printnum(e2_mag_emm_abs_z.ratio)`, p `r printp(e2_mag_emm_abs_p.value)`). Therefore, the interaction indicates that the magnitude of influence exerted by a bar chart's axis varied according to whether the denominator was present or absent.

This model employed by-participant and by-item random effects. For each participant, there were random intercepts, plus random slopes for axis settings and denominator information. For each item, there were random intercepts, plus random slopes for denominator information. The model formula was as follows: `r print_formula(e2_mag)`.

```{r}
#| label: fig-e2-mag-int
#| out-width: "500px"
#| include: true
#| message: false
#| fig-scap: The interaction between axis limits and denominator information, for magnitude ratings. 
#| fig-cap: The interaction between axis limits and denominator information, for magnitude ratings. Estimated marginal means are generated by the linear mixed model used in analysis. Translucent bars show 95% confidence intervals.

my_palette <- unname(palette.colors(palette = "Okabe-Ito")[2:3])

emmip(e2_mag@model, axis ~ denominator, CIs = T, 
      dotarg = list(shape = "circle", size = 2), 
      linearg = list(linetype = "solid", lwd = 1.5),
      CIarg = list(lwd = 3, alpha = 0.5)) +
  scale_x_discrete(limits = c('pres', 'abs'), 
                   labels = c('Present in text', 'Absent from text')) +
  scale_color_manual(limits = c('default', 'extend'), 
                       labels = c('Default', 'Extended'),
                   values = my_palette) +
  scale_y_continuous(limits = c(1,2), 
                     breaks = c(1,2), 
                     minor_breaks = seq(1,2,0.2),
                     labels = c('Very low\nmagnitude', 
                                'Very high\nmagnitude')) + 
  labs(color = "Axis Limit",
       y = "Magnitude Rating",
       x = "Denominator in Text",
       title = "Experiment 2 - Magnitude Ratings",
       subtitle =  "Estimated Marginal Means") + 
  theme_minimal(base_size = 10)
```

#### Magnitude Ratings and Data Visualisation Literacy

```{r}
#| label: e2-lit
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_mag_l <- lmer(add.terms(formula(e2_mag),
"literacy"),
              data = e2)
```

```{r}
#| label: e2-mag-lint
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_mag_lint <- buildmer(mag_slider.response ~ axis*denominator*literacy +
                     (1 + axis*denominator | participant) + 
                     (1 + axis*denominator*literacy | item_no),
                   buildmerControl=list(                         include='mag_slider.response ~ axis*denominator*literacy'),
                     data = e2)

emtrends(e2_mag_lint@model, pairwise ~ axis:denominator, var = "literacy")

emmip(e2_mag_lint@model, axis:denominator ~ literacy, cov.reduce = range) 

```

```{r}
#| label: e2-mag-statistics
summary_extract(e2_mag_l)
summary_extract(e2_mag_lint)

emtrends(e2_mag_lint@model, pairwise ~ axis:denominator, var = "literacy")$emtrends %>%
  as_tibble() %>% 
  mutate(comb = paste0(axis, denominator)) %>%
  group_split(comb) %>% map(~ {
    vals <- as.list(.x)
    names(vals) <- paste0("e2_mag_lint", 
                          "_", 
                          .x$comb, 
                          "_", 
                          names(vals))
    list2env(vals, envir = globalenv())
})
```

Accounting for differences in data visualisation literacy did not change the the main effect of axis limits (F(`r printnum(e2_mag_l_axis_NumDF)`, `r printnum(e2_mag_l_axis_DenDF)`) = `r printnum(e2_mag_l_axis_F.value)`, p `r printp(e2_mag_l_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_l_axis_Eta2_partial)`), the main effect of denominator information (F(`r printnum(e2_mag_l_denominator_NumDF)`, `r printnum(e2_mag_l_denominator_DenDF)`) = `r printnum(e2_mag_l_denominator_F.value)`, p `r printp(e2_mag_l_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_l_denominator_Eta2_partial)`), or the significant interaction: F(`r printnum(e2_mag_l_axis_denominator_NumDF)`, `r printnum(e2_mag_l_axis_denominator_DenDF)`) = `r printnum(e2_mag_l_axis_denominator_F.value)`, p `r printp(e2_mag_l_axis_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_l_axis_denominator_Eta2_partial)`.

An exploratory analysis revealed that there was no interaction between data visualisation literacy and axis limits (F(`r printnum(e2_mag_lint_axis_literacy_NumDF)`, `r printnum(e2_mag_lint_axis_literacy_DenDF)`) = `r printnum(e2_mag_lint_axis_literacy_F.value)`, p `r printp(e2_mag_lint_axis_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_lint_axis_literacy_Eta2_partial)`), however there was an interaction between data visualisation literacy and denominator information (F(`r printnum(e2_mag_lint_denominator_literacy_NumDF)`, `r printnum(e2_mag_lint_denominator_literacy_DenDF)`) = `r printnum(e2_mag_lint_denominator_literacy_F.value)`, p `r printp(e2_mag_lint_denominator_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_lint_denominator_literacy_Eta2_partial)`).

There was also a significant three-way interaction between data visualisation literacy, axis limits, and denominator information: F(`r printnum(e2_mag_lint_axis_denominator_literacy_NumDF)`, `r printnum(e2_mag_lint_axis_denominator_literacy_DenDF)`) = `r printnum(e2_mag_lint_axis_denominator_literacy_F.value)`, p `r printp(e2_mag_lint_axis_denominator_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_lint_axis_denominator_literacy_Eta2_partial)`. When denominator information was *present*, a one unit increase in data visualisation literacy *changed* magnitude ratings for default charts by `r printnum(e2_mag_lint_defaultpres_literacy.trend)`, but *changed* magnitude ratings for extended charts by `r printnum(e2_mag_lint_extendpres_literacy.trend)`. When denominator information was *absent*, a one unit increase in data visualisation literacy *changed* magnitude ratings for default charts by `r printnum(e2_mag_lint_defaultabs_literacy.trend)`, but *changed* magnitude ratings for extended charts by `r printnum(e2_mag_lint_extendabs_literacy.trend)`.

```{r}
#| label: fig-e2-mag-lint
#| out-width: "500px"
#| include: true
#| warning: false
denom_labs <- c("Denominator Present in Text", 
                 "Denominator Absent from Text")
names(denom_labs) <- c("pres", "abs")

emmip(e2_mag_lint@model, axis ~ literacy | denominator, cov.reduce = range, CIs = T, 
      linearg = list(linetype = "solid", lwd = 1.5)) +
  scale_color_manual(limits = c('default', 'extend'), 
                       labels = c('Default', 'Extended'),
                   values = my_palette) +
  scale_y_continuous(limits = c(1,2), 
                     breaks = c(1,2), 
                     minor_breaks = seq(1,2,0.2),
                     labels = c('Very low\nmagnitude', 
                                'Very high\nmagnitude')) + 
  labs(color = "Axis Limit",
       y = "Magnitude Rating",
       x = "Data Visualisation Literacy",
       title = "Experiment 2 - Data Visualisation Literacy Interactions",
       subtitle =  "Estimated Marginal Means") + 
  theme_minimal(base_size = 10) +
  facet_wrap(vars(denominator), labeller = labeller(denominator = denom_labs))
```

#### Confidence Ratings

```{r}
#| label: fig-e2-con
#| include: true
#| message: false
#| out-width: "500px"
#| fig-asp: 1
#| fig-scap: The distribution of confidence ratings in response to default and extended axis limits, shown separately for trials where denominator values were absent from accompanying text, and trials where denominator values were present in accompanying text.
#| fig-cap: The distribution of confidence ratings in response to default and extended axis limits, shown separately for trials where denominator values were absent from accompanying text (top), and trials where denominator values were present in accompanying text (bottom). Each circle represents a participant's response to an individual bar chart.

denom_labs <- c("Denominator Present in Text", 
                 "Denominator Absent from Text")
names(denom_labs) <- c("pres", "abs")

e2 %>%
  ggplot(aes(x = con_slider.response, 
             y = axis)) +
  geom_density_ridges(scale = 0,
                      colour = "lightgrey",
                      alpha = 0,
                      jittered_points = T,
                      position = position_raincloud(height = 0.3),
                      point_alpha = 0.05,
                      point_colour = "black",
                      point_size = 0.75) +
  geom_density_ridges(aes(height = after_stat(density)),
                      stat = "density",
                      scale = 0.5,
                      colour = "black",
                      fill = "darkgrey",
                      panel_scaling = FALSE) +
  geom_boxplot(outlier.shape=NA,
             width = 0.10,
             colour = "white",
             fill = "white",
             alpha = 0,
             lwd = 1,
             position = position_nudge(y=-.2)) +
  geom_boxplot(outlier.shape=NA,
               width = 0.09,
               colour = "black",
               fill = "white",
               alpha = 0.7,
               lwd = 0.5,
               position = position_nudge(y=-.2)) +
  scale_y_discrete(limits = c("extend", "default"),
                   labels = c("Extended\nAxis Limit", "Default\nAxis Limit")) + 
  labs(title = "Experiment 2 - Distribution of Confidence Ratings",
       subtitle =  "Density Plots, Boxplots, and Raw Data",
       y = NULL,
       x = NULL) + 
  scale_x_continuous(labels = c('Very\nconfident', 'Not very\nconfident'),
                     breaks = c(1,2),
                     minor_breaks = c()) + 
  facet_wrap(vars(denominator), ncol = 1, labeller = labeller(denominator = denom_labs)) +
  theme_minimal(base_size = 10) +
  theme(aspect.ratio = 0.6)
```

@fig-e2-con shows the distribution of confidence ratings for charts with default axes and extended axes, where denominators were absent from text, and where they were present.

```{r}
#| label: e2-con
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_con <- buildmer(con_slider.response ~ axis*denominator +
                     (1 + axis*denominator | participant) + 
                     (1 + axis*denominator | item_no),
                   data = e2)
```

```{r}
#| label: e2-con-anova
#| message: false

e2_con_summ <- anova(e2_con) %>% as_tibble(rownames = "FixEf", .name_repair = make.names) %>%
  rename("Pr" = "Pr..F.")
summary_extract(e2_con)
```

```{r}
#| label: e2-con-contrasts

e2_con_emm <- emmeans(e2_con@model, pairwise ~ axis * denominator, adjust = 'sidak') 
  
get_contrasts(e2_con_emm, condition = "denominator")
```

```{r}
#| label: fig-e2-con-int
#| include: true
#| out-width: "500px"
#| message: false
#| fig-scap: The interaction between axis limits and denominator information, for confidence ratings.
#| fig-cap: The interaction between axis limits and denominator information, for confidence ratings. Estimated marginal means are generated by the linear mixed model used in analysis. Translucent bars show 95% confidence intervals.

my_palette <- unname(palette.colors(palette = "Okabe-Ito")[2:3])

emmip(e2_con@model, denominator ~ axis, 
      CIs = T, 
      dotarg = list(shape = "circle", size = 2), 
      linearg = list(linetype = "solid", lwd = 1.5),
      CIarg = list(lwd = 3, alpha = 0.5)) +
  scale_color_manual(limits = c('abs', 'pres'), 
                   labels = c('Absent from text', 'Present in text'),
                   values = my_palette,
                   guide = guide_legend(reverse=T)) +
  scale_x_discrete(limits = c('extend', 'default'), 
                       labels = c('Extended', 'Default')) +
  scale_y_continuous(limits = c(1,2), 
                     breaks = c(1,2), 
                     minor_breaks = seq(1,2,0.2),
                     labels = c('Not very\nconfident', 
                                'Very\nconfident')) + 
  labs(x = "Axis Limit",
       y = "Confidence Rating",
       color = "Denominator in Text",
       title = "Experiment 2 - Confidence Ratings",
       subtitle =  "Estimated Marginal Means") + 
  theme_minimal(base_size = 10) 
```

A mixed effects model revealed a main effect associated with axis limits (F(`r printnum(e2_con_axis_NumDF)`, `r printnum(e2_con_axis_DenDF)`) = `r printnum(e2_con_axis_F.value)`, p `r printp(e2_con_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_axis_Eta2_partial)`), a main effect associated with denominator information (F(`r printnum(e2_con_denominator_NumDF)`, `r printnum(e2_con_denominator_DenDF)`) = `r printnum(e2_con_denominator_F.value)`, p `r printp(e2_con_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_denominator_Eta2_partial)`) and an interaction F(`r printnum(e2_con_denominator_axis_NumDF)`, `r printnum(e2_con_denominator_axis_DenDF)`) = `r printnum(e2_con_denominator_axis_F.value)`, p `r printp(e2_con_denominator_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_denominator_axis_Eta2_partial)`. This interaction consisted of a difference between extended and default charts when the denominator was absent from text (z = `r printnum(e2_con_emm_abs_z.ratio)`, p `r printp(e2_con_emm_abs_p.value)`), but no difference between charts when the denominator was present (z = `r printnum(e2_con_emm_pres_z.ratio)`, p `r printp(e2_con_emm_pres_p.value, add_equals = TRUE)`). However, it is clear from @fig-e2-con-int, as well as the partial $\eta^2$ values, that the effect sizes associated with axis limits and the interaction are trivial.

This model employed by-participant and by-item random effects. For each participant, there were random intercepts, plus random slopes for axis settings and denominator information. For each item, there were random intercepts, plus random slopes for denominator information. The model formula was as follows: `r print(print_formula(e2_con))`.

#### Confidence Ratings and Data Visualisation Literacy

```{r}
#| label: e2-con-lit
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_con_l <- lmer(add.terms(formula(e2_con),
"literacy"),
              data = e2)
```

```{r}
#| label: e2-con-lint
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_con_lint <- buildmer(con_slider.response ~ axis*denominator*literacy +
                     (1 + axis*denominator | participant) + 
                     (1 + axis*denominator*literacy | item_no),
                   buildmerControl=list(                         include='con_slider.response ~ axis*denominator*literacy'),
                     data = e2)

emtrends(e2_con_lint@model, pairwise ~ axis:denominator, var = "literacy")

emmip(e2_con_lint@model, axis:denominator ~ literacy, cov.reduce = range) 
```

```{r}
#| label: e2-con-statistics
summary_extract(e2_con_l)
summary_extract(e2_con_lint)
```

Accounting for differences in data visualisation literacy did not change the pattern of results. There was a main effect associated with axis limits (F(`r printnum(e2_con_l_axis_NumDF)`, `r printnum(e2_con_l_axis_DenDF)`) = `r printnum(e2_con_l_axis_F.value)`, p `r printp(e2_con_l_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_l_axis_Eta2_partial)`) and a main effect associated with denominator information (F(`r printnum(e2_con_l_denominator_NumDF)`, `r printnum(e2_con_l_denominator_DenDF)`) = `r printnum(e2_con_l_denominator_F.value)`, p `r printp(e2_con_l_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_l_denominator_Eta2_partial)`) and an interaction F(`r printnum(e2_con_l_denominator_axis_NumDF)`, `r printnum(e2_con_l_denominator_axis_DenDF)`) = `r printnum(e2_con_l_denominator_axis_F.value)`, p `r printp(e2_con_l_denominator_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_l_denominator_axis_Eta2_partial)`.

An exploratory analysis revealed that there was no interaction between data visualisation literacy and axis limits (F(`r printnum(e2_con_lint_axis_literacy_NumDF)`, `r printnum(e2_con_lint_axis_literacy_DenDF)`) = `r printnum(e2_con_lint_axis_literacy_F.value)`, p `r printp(e2_con_lint_axis_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_lint_axis_literacy_Eta2_partial)`), no interaction between data visualisation literacy and denominator information (F(`r printnum(e2_con_lint_denominator_literacy_NumDF)`, `r printnum(e2_con_lint_denominator_literacy_DenDF)`) = `r printnum(e2_con_lint_denominator_literacy_F.value)`, p `r printp(e2_con_lint_denominator_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_lint_denominator_literacy_Eta2_partial)`), and no three-way interaction between data visualisation literacy, axis limits, and denominator information (F(`r printnum(e2_con_lint_axis_denominator_literacy_NumDF)`, `r printnum(e2_con_lint_axis_denominator_literacy_DenDF)`) = `r printnum(e2_con_lint_axis_denominator_literacy_F.value)`, p `r printp(e2_con_lint_axis_denominator_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_lint_axis_denominator_literacy_Eta2_partial)`).

### Discussion

This experiment manipulated bar charts' axis limits and the presence of denominator values in accompanying text. The results demonstrate that values presented in charts with default axis limits are associated with higher magnitude judgements than charts with extended axes, in both the presence and absence of denominator information. However, the absence of denominator information amplifies this bias. These results also suggest that extreme high magnitude ratings for default charts in the presence of a denominator value may be driven by a failure to incorporate that value into reasoning. Finally, confidence in judgements is reliably affected by the inclusion of denominator information in text.

## General Discussion

Axis limits can be easily manipulated in common data visualisation software, in order to include a visual cue to denominator information. However, these defaults are based on plotted data only, so often omit denominator information. We demonstrate that plotted values' magnitudes were interpreted as smaller for bar charts with axes that extended to the denominator value, rather than those employing default axis settings. The influence of axis limits was particularly large when no denominator information was included in the text accompanying a chart. This provides insight into the cognitive process involved in magnitude judgements, indicating that denominator information is an important aspect in interpreting plotted values in bar charts.

In Experiment 1, we identified a framing effect, wherein charts with axes that accommodated a denominator value elicited smaller magnitude judgements compared to charts with default axes. In both conditions, the denominator was explicitly presented in the text. Additionally, some extreme responses in the default condition appeared to represent a disregard for denominator information. Given the apparent importance of this information, we conducted another experiment in order to examine the denominator's role in the cognitive processing of magnitude. We examined how interpretations were affected by the absence of denominator information, thus capturing how this information was incorporated differently across chart designs.

Experiment 2 makes several additional contributions. First, it replicated the main effect from Experiment 1. That is, we observed a propensity to interpret magnitudes as smaller when values were shown with an extended axis, rather than a default axis. Second, it illustrates the impact of including the denominator in accompanying text. This cue affects viewers' interpretations differently depending on whether a chart's axis also incorporates the same value. Without denominator information in text, the magnitude of values plotted using default axes can be ambiguous. Accordingly, drastically higher ratings in the absence of denominator information illustrate the denominator's role in reducing ambiguity. Interpretation of values plotted using extended axes was affected to a lesser extent by the denominator's absence. Thus, the impact of a bar chart's axis is greater when not accompanied by a denominator. This suggests axis limits facilitate recognition of denominator information when interpreting magnitudes.

Third, Experiment 2 replicated the pattern of responses observed in Experiment 1 for charts with default axes and accompanying denominator information. This pattern consists of a small number of higher magnitude ratings, in contrast to the general tendency for lower magnitude ratings. @fig-e2-mag reveals a close resemblance between the distribution of these higher ratings and the overall distribution of ratings for default charts *without* accompanying denominator information. This suggests that these extreme ratings may share a cause. Unusually high responses in the presence of denominator information likely result from failure to account for the denominator and a subsequent reliance on the chart's appearance. The analogous responses to charts without accompanying denominators (Experiment 2) can be considered an experimentally-induced instance of the same effect.

Fourth, additional ratings collected in Experiment 2 provide insight into participants' confidence. Although analysis of these ratings indicated a main effect of axis limits and an interaction between denominator information and axis limits, the minuscule effect sizes cast doubt over the practical significance of these effects. In spite of this, absence of a denominator clearly lowered confidence. This suggests that participants were hesitant to form magnitude judgements based solely on a bar chart's appearance. Inclusion of a denominator value in text was preferred regardless of graphical cues to context.

### Relationship to Prior Work

Our focus on judgements of values' magnitudes is noteworthy because the vast majority of related work has explored participants' judgements of *differences between* values [@okan_individual_2012; @okan_probability_2020; @okan_designing_2018; @stone_foregroundbackground_2003; @stone_salience_2018; @garcia-retamero_who_2010; @yang_truncating_2021; @witt_graph_2019; @correll_truncating_2020]. Responses to questions about values' magnitudes have often been obscured through inclusion in composite measures [e.g., @okan_designing_2018], or have been collected to assess comprehension, rather than interpretation [e.g., @garcia-retamero_who_2010]. As @stone_effects_2015 discuss, failing to consider interpretations of values' magnitudes reflects two issues. First, neglecting values' magnitudes overlooks a relevant aspect of numerical information. Second, neglecting participants' *interpretations* limits insight into decision-making, which is not simply governed by accurate retrieval of information [see @reyna_theory_2008].

Whereas much prior research has been limited to interpretation of risk information [@garcia-retamero_who_2010; @okan_individual_2012; @okan_probability_2020; @okan_designing_2018; @stone_foregroundbackground_2003; @stone_salience_2018; @stone_designing_2017; @stone_effects_2015], we demonstrate that biases in interpretation extend to a wide range of non-risk scenarios. This provides confidence that these findings are widely applicable, and using *multiple* trials per participant enhances statistical power. When generating charts that do not include denominator values, previous experiments [@garcia-retamero_who_2010; @okan_designing_2018] appear to have employed arbitrary axis limits. By employing axis limits based on {ggplot2}'s default settings, our materials reflect a common practice, enhancing our experiment's ecological validity.

We contribute to a large body of evidence illustrating biases in the interpretation of numerical information, specifically *framing effects* [@tversky_framing_1981]. Our results are consistent with research demonstrating that manipulating bar charts' axis limits influences interpretation of plotted values [@garcia-retamero_who_2010; @okan_designing_2018]. Furthermore, @okan_designing_2018 found that participants' perceptions of risk were influenced more by bar charts' axis limits when labels containing numerators and denominators were excluded. Similarly, we observed that interpretations of magnitude were influenced more by bar charts' axis limits when denominator values were omitted from accompanying text.

A previous study exploring interpretation of magnitude in bar charts observed different responses according to whether stacked bars or blank space conveyed alternative outcomes [@stone_designing_2017]. We demonstrate that manipulating the amount of blank space above bars can elicit different magnitude judgements, without plotting alternative outcomes explicitly. Earlier work investigating (in)consistency in the formats used to display numerators and denominators is also relevant. @stone_effects_2015 found that displaying a value using icons, accompanied by a denominator in text, increased impressions of that value's magnitude, compared to when both the value and denominator were presented in text. We too found higher ratings when values displayed using bars were only accompanied by a denominator in text, compared to when a corresponding graphical cue to the denominator value was also present.

According to Fuzzy Trace Theory, different interpretations can arise due to different gist-level representations, despite accurate comprehension of presented values [@reyna_theory_2008]. Therefore, access to denominator information in accompanying text did not prevent our chart designs influencing judgements. Encoding of gist is reported to be influenced by the appearance of graphical elements [@reyna_theory_2008]. This suggests that the taller bars in our default axis conditions were responsible for impressions of greater magnitude, compared to shorter bars in our extended axis conditions. That charts with extended axes elicited lower magnitude ratings is also consistent with Stone et al.'s [-@stone_salience_2018] proportional reasoning account, which suggests that part-to-whole displays facilitate processing of a larger numerical context.

We did not find evidence that data visualisation literacy affected our results. This is contrary to the finding that data visualisation literacy predicted the efficacy of using icon arrays to reduce denominator neglect [@okan_individual_2012]. However, this is consistent with the finding that the impact of manipulations like ours (axis range, numerical labels) are independent of data visualisation literacy [@okan_designing_2018]. This measure may capture whether people have sufficient ability to extract information from a visualisation, rather than predicting the degree to which they will be influenced by subtler design choices [@yang_truncating_2021]. Numeracy is associated with decreased sensitivity to framing effects [@peters_numeracy_2006], so this may be a better candidate for understanding individual differences in response to visualisation design.

### Implications

When conveying values' magnitudes, both axis limits and accompanying text warrant consideration from data visualisation designers. A bar chart produced using default settings is not equivalent to a bar chart with an axis that incorporates a denominator value. Extending an axis in this manner increases consistency in judgements and may provide insurance against individuals who fail to account for accompanying denominator information. Similarly, where constraints prevent inclusion of a denominator value in text, an extended axis should facilitate viewers' recognition of this numerical context. We observed that confidence ratings were consistently high in the absence of a denominator in text, despite use of an extended axis. Explicitly providing denominator values in text, regardless of graphical cues, would therefore promote viewers' confidence in their judgements.

It is also worth considering situations which may accentuate the observed bias. High cognitive load exacerbates the numerosity bias [@pelham_easy_1994], therefore may also interfere with magnitude judgements. Even when denominator information is supplied in text, high cognitive load could prevent this information from informing interpretations. This would likely increase reliance on bar charts' appearances, like in Experiment 2. Additionally, assuming that an audience has knowledge of a dataset's denominator may increase biases in individuals who are unfamiliar with the topic.

### Limitations and Future Work

This work is concerned with visualisations intended to convey plotted values' magnitudes. However, design considerations will differ when conveying *differences* between values. In this case, axis ranges should be determined by the magnitude of the differences [@correll_truncating_2020; @witt_graph_2019; @yang_truncating_2021]. Consequently, our recommendations are not relevant for all communicative scenarios. However, maintaining awareness of the implication of plotted values' magnitudes may help avoid misinterpretation of data, even if this type of judgement is not a primary concern.

Our experiments apply best to controlled scenarios, such as surveys and experiments where all plotted values share the same denominator. These findings may also extend to datasets with unequal denominators, if bars are used to depict proportions or percentages, permitting use of a single meaningful axis limit. However, this design will not be suitable for plotting other types of dataset. We also acknowledge that proportions are not the only factor influencing magnitude judgements: subject matter is also likely to inform assessments. For example, bars clearly depicting one or two hours spent on administrative tasks within a 35-hour work week will still elicit some differences of opinion regarding whether these values are high or low.

All materials were produced using {ggplot2}. Therefore, our conclusions about default axis limits only pertain to bar charts created using this package's settings, though we expect other visualisation libraries' default settings to elicit similar responses, due to similarity in their behaviour. For uniformity in our materials, we only employed default charts where the highest gridline was positioned below the highest value, since this was the most common visual arrangement. We did not examine the minority of cases where the highest gridline exceeds the highest value. Whether this influences magnitude judgements could be explored in future experiments. In addition, future work should employ decision-making tasks to quantify the impact of axis limits on applied judgements.

### Conclusion

In two experiments, we generated evidence on the effects of default and extended axis limits, illustrating the influential role of denominators in gauging magnitude. We provide insight into the cognitive processes involved in interpreting plotted values' magnitudes in bar charts and offer recommendations for facilitating judgements. Framing effects demonstrate the power of presentation choices on the interpretation of numbers.
