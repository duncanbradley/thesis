---
title: "Axis Limits and Denominator Information Influence Absolute Magnitude Ratings in Bar Charts"
editor: visual

params: 
  eval_models: false
  
format: pdf
    
execute:
  echo: false
  warning: true
  message: true
  include: false
  
bibliography: axis-extension.bib
---

```{r}
#| label: libraries
library(tidyverse)
library(lme4)
library(lmerTest)
library(buildmer)
library(qwraps2)
library(emmeans)
library(effectsize)
library(papaja)
library(patchwork)
library(insight)
library(knitr)
library(magick)
library(ggridges)
library(report)
library(MuMIn)
library(markdown)
library(shiny)
set.seed(45789)
```

```{r}
#| label: lazyload-cache
if (!params$eval_models){
lazyload_cache_dir('axis-extension_cache/html')}
```

```{r}
#| label: wrangle
anon_data1 <- read_csv('data/anon_data1.csv',
                       col_types = cols(.default = "?", genderResp2.text = col_character()))
# correct the coercion of the genderResp2.text to logical

anon_data2 <- read_csv('data/anon_data2.csv')

# perform necessary data wrangling
wrangle <- function(anon_file, .y) {
  # .y captures the index of the file in the list supplied to iwalk

# extract literacy data
# calculate literacy score (sum of five responses)
literacy <- anon_file %>%
  filter(!is.na(q1_slider.response)) %>%
  rowwise() %>%
  mutate(literacy = sum(c(q1_slider.response, 
                          q2_slider.response, 
                          q3_slider.response, 
                          q4_slider.response, 
                          q5_slider.response))) %>%
  select(participant,
         literacy)

# define education categories 
edu_labels <- set_names(c('No formal qualications',
                          'Secondary education (e.g. GED/GCSE)',
                          'High school diploma/A-levels',
                          'Technical/community college',
                          'Undergraduate degree (BA/BSc/other)',
                          'Graduate degree (MA/MSc/MPhil/other)',
                          'Doctorate degree (PhD/other)',
                          'Don\'t know / not applicable'),
                        seq(8,1,-1))

# define gender categories
gender_labels <- set_names(c("Pnts", 
                             "Another",
                             "NB", 
                             "M", 
                             "F"),
                           1:5)
# extract demographics
# link slider response numbers to gender categories 
# link slider response numbers to education categories
demographics <- anon_file %>%
  filter(!is.na(genderResp1.response)) %>%
  mutate(genderResp1.response = 
           recode(genderResp1.response, !!!gender_labels)) %>%
  mutate(edu_slider.response =
           recode(edu_slider.response, !!!edu_labels)) %>%
  select(participant,
         ageResp.text,
         genderResp1.response,
         edu_slider.response)

# extract duration data (in seconds)
durations <- anon_file %>%
  filter(!is.na(total_duration)) %>%
  select(participant, total_duration)
  
# select relevant columns
# select only experimental items
# add literacy and demographic data
# change data types where appropriate
# output this file with suffix 'tidy'
anon_file %>% 
  filter(item_type == "E") %>%
  select(matches(c("participant",
                   "item_no",
                   "item_type",
                   "cond",
                   "axis",
                   "denominator",
                   "slider.response",
                   "mag_slider.response",
                   "con_slider.response",
                   "seed_no"))) %>% 
    inner_join(literacy, by = "participant") %>%
    inner_join(demographics, by = "participant") %>%
    inner_join(durations, by = "participant") %>%
    mutate(total_duration = total_duration / 60) %>%
    mutate(across(matches(c("cond", "axis")), 
                  ~ case_match(.x,
                               "full" ~ "extend",
                               "trunc" ~ "default"))) %>%
    mutate(across(matches(c("axis", "denominator", "cond")), as_factor)) %>%
    mutate(across(c("participant", "item_no"), as.character)) %>%
    assign(paste0("e", .y),
           value = ., envir = .GlobalEnv)
}

iwalk(list(anon_data1, anon_data2), wrangle)


# set sum contrasts
contrasts(e2$axis) <- contr.sum(2)
contrasts(e2$denominator) <- contr.sum(2)
```

```{r}
#| label: anova-results-function
# this function takes two nested models, runs an anova, and the outputs the Likelihood Ratio Statistic, degrees of freedom, and p value to the global environment
anova_results <- function(test_model, full_model) {
  
  # first argument 
  test_model_name <- deparse(substitute(test_model))
  full_model_name <- deparse(substitute(full_model))

  if (class(test_model) == "buildmer") test_model <- test_model@model
  if (class(full_model) == "buildmer") full_model <- full_model@model
  
  anova_output <- anova(test_model, full_model)
  
  assign(paste0(test_model_name, ".Chi"),
         anova_output$Chisq[2],
         envir = .GlobalEnv)
  assign(paste0(test_model_name, ".Df"),
         anova_output$Df[2],
         envir = .GlobalEnv)
  assign(paste0(test_model_name, ".p"),
         anova_output$`Pr(>Chisq)`[2],
         envir = .GlobalEnv)
  
  es <- eta_squared(anova(full_model), partial = TRUE) 
  
  es %>% pull(Parameter) %>%
    map(function(x) assign(paste0(model_name, 
                                  ".eta.", 
                                  str_replace(x, ":", "_")),
                           es %>%
                             filter(Parameter == x) %>% 
                             pull(Eta2_partial),
                           envir = .GlobalEnv))
}
```

```{r}
#| label: summary-extract-function
# this function extracts test statistics and p values from model summaries
summary_extract <- function(model) {
  
  model_name <- deparse(substitute(model))
  
  if (class(model) == "buildmer") model <- model@model
  
  es <- eta_squared(anova(model), partial = TRUE) 

  model %>% 
    anova() %>%
    as_tibble(rownames = "term", 
              .name_repair = make.names) %>%
    rename("p" = "Pr..F.") %>%
    inner_join(es, by = join_by("term" == "Parameter")) %>%
    mutate(term = str_replace_all(term, ":", "_")) %>%
    group_split(term) %>%
    map(~ {
      vals <- as.list(.x)
      names(vals) <- paste0(model_name, 
                            "_", 
                            .x$term, 
                            "_", 
                            names(vals))
      list2env(vals, envir = globalenv())
    })
  
}
```

```{r}
#| label: get-contrasts-function

get_contrasts <- function(contrast_df, condition) {

  df_name <- deparse(substitute(contrast_df))

  contrast_df %>% 
    contrast("consec", 
             simple = "each", 
             combine = TRUE, 
             adjust = "sidak") %>%
    as_tibble() %>% 
    filter(!!sym(condition) != ".") %>%
    group_split(!!sym(condition)) %>%
    map(~ {
      vals <- as.list(.x)
      names(vals) <- paste0(df_name, 
                            "_",
                            pull(., {{condition}}),
                            "_", 
                            names(vals))
      list2env(vals, envir = globalenv())
    })
  
}
```

```{r}
#| label: get-anomalies-function

# returns the proportion of datasets which needed to re-generated for the highest data point to exceed the highest gridline

get_anomalies <- function(dataset){
  dataset %>%
  pull(seed_no) %>% # extract column with seed numbers
  unique() %>% # get unique values
  na.omit() %>% # omit NAs
  sort() %>% # ascending order (since they were generated in order)
  diff() %>% # calculate difference between each pair of values
  # the while loop was entered on every trial including the first
  # the first seed value in both experiments is 2
  # this indicates that a new seed number was not selected for the first chart
  #c(1, .) %>% # therefore we prepend a 1 to indicate this
  `>`(1) %>% # count the number of cases where a new seed number was selected
  mean()*100 # calculate the proportion of TRUE cases as a %
}
```

```{r}
#| label: print-es-function
# for dealing with effect sizes less than .001
print_es <- function(x) {ifelse(x<.01, "< .01", paste("=", printnum(x)))}
```

```{r}
#| label: print-formula
# Unfortunately, simplify.formula() ignores the common ordering for mixed effects models where fixed effects come first and random effects afterwards.
# This is solved by simplifying the fixed and random effects separately, then combining them.

print_formula <- function(model){

# simplify fixed effects only 
fixfx <- formula(model) %>% 
  nobars() %>%
  simplify.formula()

# simplify random effects only
ranfx <- formula(model) %>% 
  getrandom() %>%
  simplify.formula()

# combine fixed and random effects
# convert formula to a string in order to replace terms
# and add brackets to random effects
# then convert back to a formula
  merge.formula(fixfx, ranfx) %>%
  format_formula() %>%
  str_replace_all(c("mag_slider.response" = "magnitude", 
                      "con_slider.response" = "confidence",
                      "slider.response" = "magnitude", 
                      "axis" = "axis_limit",
                      "cond" = "axis_limit", 
                    "denominator \\+ axis_limit \\+ axis_limit:denominator" = "axis_limit * denominator",
                    '1' = '(1',
                    "item_no" = "scenario",
                  '(participant|scenario)' =  '\\1)',
                  'formula: ' = ''))
}

getrandom <- function(form) {
    
    parens <- function(x) {paste0("(",x,")")}
    onlyBars <- function(form) {
      reformulate(
        sapply(
          findbars(form), # list of character vector for each random effect
          function(x)  parens(deparse(x))), # put each character vector in brackets
        response = form[[2]]) 
    }
    
    out <- onlyBars(form)
    return(out)
}

merge.formula <- function(form1, form2, ...){
    # adapted from https://stevencarlislewalker.wordpress.com/2012/08/06/merging-combining-adding-together-two-formula-objects-in-r/
    
    # get character strings of the names for the responses 
    # (i.e. left hand sides, lhs)
    lhs1 <- deparse(form1[[2]])
    #print(lhs1)
    lhs2 <- deparse(form2[[2]])
    #print(lhs2)
    if(lhs1 != lhs2) stop('both formulas must have the same response')
    
    # get character strings of the right hand sides
    rhs1 <- strsplit(paste(form1[3]), " \\+ ")[[1]] 
    rhs2 <- strsplit(paste(form2[3]), " \\+ ")[[1]] 
    
    # put the two sides together with the amazing 
    # reformulate function
    out <- reformulate(termlabels = c(rhs1, rhs2), 
                       response = lhs1)
    
    # set the environment of the formula (i.e. where should
    # R look for variables when data aren't specified?)
    #environment(out) <- parent.frame()
    return(out)
  }
```

```{r}
#| label: gender-proportions
gender_e1 <- e1 %>%
    distinct(participant, .keep_all = TRUE) %>% 
    group_by(genderResp1.response) %>% summarise(cnt = n()) %>%
    reframe(freq = cnt / sum(cnt) *100, 
            gender = unique(genderResp1.response)) %>%
  pivot_wider(names_from = gender, values_from = freq)

gender_e2 <- e2 %>%
    distinct(participant, .keep_all = TRUE) %>% 
    group_by(genderResp1.response) %>% summarise(cnt = n()) %>%
    reframe(freq = cnt / sum(cnt) *100, 
            gender = unique(genderResp1.response)) %>%
  pivot_wider(names_from = gender, values_from = freq)
```

## Abstract

Consider a statistic corresponding to the number of public transport users in a particular town. Gauging whether this number is large or small requires awareness of the total population (the denominator). In data visualisations, an axis which extends beyond plotted values can act as a graphical cue to a denominator value, but default upper axis limits (e.g., in *ggplot2*) are typically based on the highest plotted value. In two experiments (combined *N* = 350), we explore the influence of default and extended axes on interpretations of magnitude in bar charts. We observe that values plotted using default axes were rated as higher, compared to values plotted using extended axes. Furthermore, the absence of denominator information in accompanying text amplifies the effect of axis limits on judgements. Whereas prior work has often focused on judgements of the *differences between values*, this work contributes to an understanding of how viewers interpret the magnitudes of *the values themselves*. We also discuss implications for effective design, which involve considering both axis limits and accompanying contextual information.

## Introduction

The question 'Is it a big number?' is often raised on the BBC radio programme *More or Less* when probing eye-catching statistics. A figure of several million pounds may initially seem large, but may represent a small proportion of total government spending. Awareness of a denominator value can influence judgement of a number's magnitude. In data visualisation, this contextual information can be displayed by extending an axis to accommodate the denominator value. However, this approach is infrequently used, since default axis settings are typically based on plotted data only. In this study, we explore how these axis limits affect interpretations of how large or small plotted values are.

### Overview

Across two experiments, we investigate the interpretation of magnitudes in bar charts. We plotted fictitious datasets, which contained multiple observations with the same denominator value. In the first experiment, we displayed charts with default axes which terminated just above plotted values, or axes which extended to the denominator value specified in accompanying text. Participants rated values' magnitudes as higher when default axes were used, compared to extended axes. In the second experiment, we manipulated the axis limits, as before, and also the presence of the denominator information in accompanying text. Variation in responses to the two different axis settings was greater when denominator information was not supplied. This indicates that this information influences the biasing effect of a chart's appearance.

### Related Work

#### Biased Interpretation of Numerical Information

A wealth of research demonstrates biases in the interpretation of numbers. A survival rate elicits different judgements of a disease compared to its corresponding mortality rate [@tversky_framing_1981], and the fat content of a meat product elicits different judgements of the product compared to its corresponding lean content [@levin_associative_1987]. The units used to express the same values (e.g., months vs. years) affect comparisons [@burson_six_2009; @monga_years_2012] and also interpretations of precision and accuracy [@zhang_how_2012].

Various biases in magnitude judgements reveal the importance of accounting for numerical context. Base rate neglect describes difficulty acknowledging population-level characteristics when making judgements about a sample [@cosmides_are_1996]. Format neglect describes a bias against incorporating set size information when judging percentage formats (e.g., top 20%) and numerical formats [e.g., top 10, @sevilla_format_2018]. Denominator neglect involves over-weighting numerator information at the expense of denominator information [@reyna_numeracy_2008]. The latter also leads (in part) to large percentages of a small number appearing greater than the *numerically equivalent* smaller percentages of a larger number [@li_big_2013]. The general mechanism responsible for these biases is a failure to properly acknowledge numerical context.

#### Visualising Denominator Information

Data visualisations can help combat biases. Denominator information becomes visually available when icon arrays present both focal outcomes (e.g., number deceased) *and also* alternative outcomes (e.g., number survived). Research suggests that providing this visual cue to a denominator (e.g., total number at risk) facilitates reasoning. For example, including alternative outcomes in an icon array reduces denominator neglect, increasing comprehension of relative risk [@garcia-retamero_who_2010]. Icon arrays displaying both types of outcome are particularly helpful for understanding datasets with unequal denominators, and for individuals with high graph literacy [@okan_individual_2012]. However, these effects are largest when depicting small probabilities [@okan_probability_2020].

Stacked bar charts function similarly to icon arrays: one bar represents the focal outcome, another bar represents the alternative outcome, and their combination represents the denominator. Like icon arrays, stacked bar charts diminish the influence of denominator neglect [@stone_foregroundbackground_2003]. Despite this, denominator information can be displayed in bar charts *without* using additional stacked bars to represent alternative outcomes. Extending an axis to incorporate a denominator value also communicates relevant numerical context. In this case, the blank space between the bars for the focal outcome and the upper axis limit corresponds to the alternative outcome. Research has demonstrated that bar charts representing alternative outcomes using blank space increase perceptions of risk likelihood compared to those representing alternative outcomes using stacked bars [@stone_designing_2017]. However, this research did not manipulate the presentation of denominator information, since identical axis limits were employed across conditions.

Directly manipulating bar charts' upper axis limits provides insight into the use of this cue to denominator information. Bar charts with axes which extend to the denominator value produce more accurate estimates of changes in risk than those with axes which terminate near the highest value [@garcia-retamero_who_2010]. Incorporating a denominator also elicits decreased ratings of risk perception [@okan_designing_2018], though numerical labels reduce this effect.

Various accounts have sought to explain the effects of including denominator information in visualisations. Depicting denominators may facilitate understanding of part-to-whole relationships, diminishing the class-inclusion errors associated with denominator neglect [@reyna_theory_2008]. This argument is consistent with Fuzzy Trace Theory, which also predicts the influence of physical attributes in gist representations [i.e, short bars may elicit smaller magnitude judgements, @reyna_theory_2008]. Additionally, @stone_salience_2018 suggest that facilitation of *proportional reasoning* may be largely responsible for observed effects. They observed that increasing the salience of the denominator in *text* fails to affect judgements, yet a *graphical* representation effectively communicates the true scale of the denominator, helping put numerators into perspective.

#### Judgements of Absolute Magnitude

As discussed above, @garcia-retamero_who_2010 and @okan_designing_2018 demonstrate that extending axes to incorporate denominator values influences interpretation of risk. However, these studies do not provide specific evidence on how this affects interpretations of the *absolute magnitude* of plotted values.

@garcia-retamero_who_2010 measured risk understanding: how faithfully participants represented the exact numbers displayed. Only assessing *comprehension* fails to capture individuals' *impressions* of plotted information [@stone_effects_2015]. Understanding the 'gist' obtained from a visualisation is crucial since this takes precedence over 'verbatim' information when making decisions [@reyna_theory_2008]. @reyna_theory_2008 argues that assessing gist requires consideration of how the *absolute* magnitude of values is interpreted, since *relative* differences are only one aspect of a dataset conveyed by a visualisation.

@okan_designing_2018 collected magnitude ratings, yet these cannot be examined in isolation, since they were assimilated into a combined measure of perceived risk, along with ratings of the degree of *difference between* plotted values. Outside the risk communication literature, a substantial body of research has also demonstrated that axis range affects judgements of the difference between values [@pandey_how_2015; @witt_graph_2019; @correll_truncating_2020; @yang_truncating_2021]. In spite of this, research has typically neglected the effects of axis range on judgements of the magnitude of *the values themselves*. @sandman_high_1994 observed that manipulating axis limits in risk ladders influenced absolute magnitude judgements, but did not use axes to convey denominators. This is the focus of the experiments presented in this work.

Prior work on extending axes did not disclose methods for determining axis limits in charts without denominators. The values used as upper limits appear to be arbitrary. In the present study, we increase ecological validity by employing default axis limits from *ggplot2* [@wickham_ggplot2_2016], a popular visualisation tool used in the R programming environment. Furthermore, previous studies' statistical power and generalisability have been limited by the use of one [@okan_designing_2018] or two [@garcia-retamero_who_2010] trials per participant. Our experiments explore a range of scenarios, with 32 experimental trials per participant. The data presented are also unrelated to risk judgements, the domain of prior research on this topic.

### Open Research Statement

Pre-registrations, experiment scripts, materials, data, and analysis code are available at <https://osf.io/rx2b7/>. A Dockerfile is also included to facilitate reproduction of the computational environment used for analysis, allowing generation of a fully-reproducible version of this paper.

## Experiment 1

### Introduction

This experiment investigates the influence of axis limits on interpretations of the magnitude of plotted values. Participants viewed bar charts with default axes, or axes which extended to a denominator value well above the bars. Comparing participants' interpretations captures the influence of displaying the same data with and without numerical context.

### Method

#### Materials

We developed 40 scenarios about fictitious studies (e.g., a quality control study). Each fictitious study evaluated a specific outcome across five categories (e.g., the number of items produced without defects, for five manufacturing methods). The denominator (e.g., total number of items produced) was identical for each category in a given scenario.

We generated bar charts in R [@r_core_team_r_2022, version 4.1.2] using *ggplot2* (version 3.4.1), *tidyverse* (version 1.3.1) and *ggh4x* (version 0.2.1). The two versions of each chart displayed the same five values, but employed different y-axis limits. Denominator values (400, 500, or 600) were used to generate datasets: data were sampled from a normal distribution with a mean equal to either 20% or 40% of a given denominator value, and a standard deviation equal to 1% of the denominator value.

For charts with extended axes, the denominator value was used as the y-axis upper limit. The other charts used a y-axis upper limit which was dictated by *ggplot2*'s default axis settings. These settings automatically identify a set of convenient breaks for each dataset, then slightly extend the plot area, adding an additional 5% of the original axis range. In both conditions, a smaller expansion factor of 1% was applied to the lower axis limit, in order to eliminate visible space below the 0 baseline. @fig-example-charts shows example charts for both conditions.

```{r}
#| label: fig-example-charts
#| include: true
#| out-width: "500px"
#| fig-scap: Example charts for Experiment 1.
#| fig-cap: "Example charts for Experiment 1. The same data appears in both charts. The chart with the default axes (left) employs an upper limit determined by ggplot2. The chart with the extended axes (right) employs an upper limit equal to the dataset's denominator value. Accompanying text explained what the values represented: 'The graph shows, for each manufacturing method, how many of the items were free from defects'."
img1 <- image_read("images/E14trunc.png")
img2 <- image_read("images/E14full.png")
image_append(c(img1, img2))
```

For the majority of datasets generated, the default settings produced charts where the highest gridline did not exceed the tallest bar. For consistency, when the opposite situation occurred, we used a different random seed to generate an alternative dataset for both conditions. `r printnum(get_anomalies(e1), digits = 0)`% of datasets used were generated using this method.

In experimental trials (32 total), plotted values consisted of relatively small proportions of the dataset's denominator value (approximately 20% or approximately 40%). To introduce variety and encourage attention, eight filler trials showed plotted values which were roughly 90% of the corresponding denominator value. Denominators for filler trials were selected so that numerical labels on the y-axis would approximately resemble the y-axis labels of extended and default bar charts from experimental trials.

We included six attention check trials to assess participants' engagement with the task. These trials were similar to experimental and filler trials, consisting of text, a bar chart, a question and a visual analogue scale. However, participants were instructed to ignore the bar chart and provide a specified response on the visual analogue scale.

#### Design

We employed a within-participants design: participants viewed 16 different charts in each of the two conditions (32 experimental trials total). The correspondence between scenarios and conditions was counterbalanced using two lists. However, all participants saw the same versions of the eight filler items and six attention check items. There were a total of 46 trials, which were presented in a random order.

#### Procedure

We programmed the experiment using PsychoPy [version 2022.1.4, @peirce_psychopy2_2019]. Participants were instructed to carry out the experiment using a laptop or desktop computer (not a mobile phone or tablet). After providing informed consent, participants completed a demographic questionnaire and Garcia-Retamero et al.'s [-@garcia-retamero_measuring_2016] five-item subjective data visualisation literacy scale.

Participants were asked to imagine they were a researcher tasked with determining the outcome of experiments and surveys. They were instructed to provide an overall assessment of all data presented in a graph after studying the text, graph, and question. The questions asked about plotted values' magnitudes (e.g., 'How successful were the manufacturing methods?'), with participants responding on visual analogue scales with anchors at the extremes (e.g., 'Very unsuccessful', 'Very successful'). @fig-e1-trial shows an example trial.

```{r}
#| label: fig-e1-trial
#| include: true
#| out-width: "500px"
#| fig-scap: An example trial from Experiment 1, showing a bar chart with a default axis limit. 
#| fig-cap: An example trial from Experiment 1, showing a bar chart with a default axis limit. 
include_graphics("images/trial_e1.png")
```

Participants were permitted to move the response marker as many times as they liked before proceeding to the next trial, but could not return to previous trials. The response scale's granularity was altered for each attention check item, such that participants could only respond at the extremes or the middle of the scale. Finally, participants were informed that all data presented was fictitious and were given the option to provide comments on the experiment and describe any strategies used. Average completion time was `r printnum(e1 %>% pull(total_duration) %>% mean(), digits = 1)` minutes.

#### Participants

Participants were recruited using Prolific.co. The experiment was advertised to fluent English speakers with normal-or-corrected to normal vision, who had previously participated in at least 100 studies on the site.

Data were returned by 157 participants. Per pre-registered exclusion criteria, seven participants' submissions were rejected because they answered more than one of six attention check questions incorrectly. Participants whose submissions were accepted received £3.50.

The final sample consisted of 150 participants (`r printnum(gender_e1$M, digits = 1)`% male, `r printnum(gender_e1$F, digits = 1)`% female, `r printnum(gender_e1$NB, digits = 1)`% non-binary). Mean age was `r printnum(e1 %>% pull(ageResp.text) %>% mean())` years (*SD* = `r printnum(e1 %>% pull(ageResp.text) %>% sd())`). The mean data visualisation literacy score was `r printnum(e1 %>% pull(literacy) %>% mean())` (*SD* = `r printnum(e1 %>% pull(literacy) %>% sd())`), out of a maximum of 30.

This experiment was approved by the University of Manchester's Division of Neuroscience and Experimental Psychology Ethics Committee (ethics code: 2022-11115-24245).

### Analysis

We conducted analysis using R [@r_core_team_r_2022, version 4.2.1]. Linear mixed models were built using *lme4* [@bates_fitting_2015]. Each initial model was based on a maximal model with random intercepts and slopes for participants and scenarios [@barr_random_2013]. The *buildmer* package [@voeten_buildmer_2022] was used to identify the final random effects structure, ensuring convergence and removing terms not significantly contributing to explaining variance.

#### Magnitude Ratings

@fig-e1-mag shows the distribution of ratings for charts with default axes and extended axes.

```{r}
#| label: fig-e1-mag
#| include: true
#| message: false
#| out-width: "500px"
#| fig-scap: The distribution of visual analogue scale ratings in response to default and extended axis limits. 
#| fig-cap: The distribution of visual analogue scale ratings in response to default and extended axis limits. Each circle represents a participant's response to an individual bar chart. Note charts with a default axis limit have a higher median value (represented by the line in the centre of the boxplot) and have a larger proportion of ratings near the 'Very high magnitude' end of the scale, compared to charts with an extended axis limit.
e1 %>%
  ggplot(aes(x = slider.response, 
             y = cond)) +
  geom_density_ridges(scale = 0,
                      colour = "lightgrey",
                      alpha = 0,
                      jittered_points = T,
                      position = position_raincloud(height = 0.3),
                      point_alpha = 0.05,
                      point_colour = "black",
                      point_size = 0.75) +
  geom_density_ridges(aes(height = after_stat(density)),
                      stat = "density",
                      scale = 0.5,
                      colour = "black",
                      fill = "darkgrey",
                      panel_scaling = FALSE) +
  geom_boxplot(outlier.shape=NA,
               width = 0.10,
               colour = "white",
               fill = "white",
               alpha = 0,
               lwd = 1,
               position = position_nudge(y=-.2)) +
  geom_boxplot(outlier.shape=NA,
               width = 0.09,
               colour = "black",
               fill = "white",
               alpha = 0.7,
               lwd = 0.5,
               position = position_nudge(y=-.2)) +
  scale_y_discrete(limits = c("extend", "default"),
                   labels = c("Extended\nAxis Limit", "Default\nAxis Limit")) + 
  labs(title = "Experiment 1\nDistribution of Magnitude Ratings",
       subtitle =  "Density Plots, Boxplots, and Raw Data",
       y = NULL,
       x = NULL) + 
  scale_x_continuous(labels = c('Very low\nmagnitude', 'Very high\nmagnitude'),
                     breaks = c(1,2),
                     minor_breaks = c()) +
  theme_minimal(base_size = 10) +
  theme(aspect.ratio = 0.6)
```

```{r}
#| label: e1-mag
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e1_mag <- buildmer(slider.response ~ cond +
                     (1 + cond | participant) + 
                     (1 + cond | item_no),
                   data = e1)
```

```{r}
summary_extract(e1_mag)
```

Linear mixed-effects modelling revealed that participants awarded higher ratings to charts with default axes, compared to charts with extended axes: F(`r printnum(e1_mag_cond_NumDF)`, `r printnum(e1_mag_cond_DenDF)`) = `r printnum(e1_mag_cond_F.value)`, p `r printp(e1_mag_cond_p, add_equals = T)`, partial $\eta^2$ = `r printnum(e1_mag_cond_Eta2_partial)` (a `r paste(interpret_eta_squared(e1_mag_cond_Eta2_partial))` effect size).

This model employed a maximal random effects structure, capturing the baseline responses (intercepts) and differences between the two axis limits (slopes) separately for each individual participant and each individual scenario. The model formula was as follows: `` `r paste(print_formula(e1_mag))` ``.

#### Magnitude Ratings and Data Visualisation Literacy

```{r}
#| label: e1-lit
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e1_mag_l <- lmer(add.terms(formula(e1_mag),
"literacy"),
              data = e1)
```

```{r}
#| label: e1-lint
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e1_mag_lint <- buildmer(slider.response ~ cond*literacy +
                     (1 + cond | participant) + 
                     (1 + cond*literacy | item_no),
                     buildmerControl=list(                         include='slider.response ~ cond*literacy'),
                   data = e1)

emtrends(e1_mag_lint@model, pairwise ~ cond, var = "literacy")

emmip(e1_mag_lint@model, cond ~ literacy, cov.reduce = range) 
```

```{r}
#| label: e1-mag-statistics
# extract test statistics
summary_extract(e1_mag_l)
summary_extract(e1_mag_lint)

emtrends(e1_mag_lint@model, "cond", var = "literacy", infer = T) %>% 
  as_tibble() %>% 
  group_split(cond) %>% map(~ {
    vals <- as.list(.x)
    names(vals) <- paste0("e1_mag_lint", 
                          "_", 
                          .x$cond, 
                          "_", 
                          names(vals))
    list2env(vals, envir = globalenv())
})
```

Accounting for differences in data visualisation literacy did not change the significant effect of axis limits: F(`r printnum(e1_mag_l_cond_NumDF)`, `r printnum(e1_mag_l_cond_DenDF)`) = `r printnum(e1_mag_l_cond_F.value)`, p `r printp(e1_mag_l_cond_p, add_equals = T)`, partial $\eta^2$ `r print_es(e1_mag_l_cond_Eta2_partial)` (a `r paste(interpret_eta_squared(e1_mag_l_cond_Eta2_partial))` effect size). This model employed the same random effects structure as above. The model formula was as follows: `` `r paste(print_formula(e1_mag_l))` ``

However, an exploratory analysis (not specified at pre-registration) revealed an interaction between data visualisation literacy and axis limits: F(`r printnum(e1_mag_lint_cond_literacy_NumDF)`, `r printnum(e1_mag_lint_cond_literacy_DenDF)`) = `r printnum(e1_mag_lint_cond_literacy_F.value)`, p `r printp(e1_mag_lint_cond_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e1_mag_lint_cond_literacy_Eta2_partial)` (a `r paste(interpret_eta_squared(e1_mag_lint_cond_literacy_Eta2_partial))` effect size). The difference between magnitude ratings for data points presented with different axis limits diminished as data visualisation literacy increased. This is shown in @fig-e1-mag-lint. This model employed random intercepts for participants, with random slopes for axis limits, plus random intercepts for items, with random slopes for axis limits. The model formula was as follows: `` `r paste(print_formula(e1_mag_lint))` ``

```{r}
#| label: fig-e1-mag-lint
#| out-width: "500px"
#| include: true
#| warning: false
#| fig-cap: The interaction between data visualisation literacy and axis limits, for magnitude ratings in Experiment 1. The data displayed are based on the estimated marginal means from the interaction model.
my_palette <- unname(palette.colors(palette = "Okabe-Ito")[2:3])

emmip(e1_mag_lint@model, cond ~ literacy, cov.reduce = range,
      linearg = list(linetype = "solid", lwd = 1.5)) +
  scale_color_manual(limits = c('default', 'extend'), 
                       labels = c('Default', 'Extended'),
                   values = my_palette) +
  scale_y_continuous(limits = c(1,2), 
                     breaks = c(1,2), 
                     minor_breaks = seq(1,2,0.2),
                     labels = c('Very low\nmagnitude', 
                                'Very high\nmagnitude')) + 
  labs(color = "Axis Limit",
       y = "Magnitude Rating",
       x = "Data Visualisation Literacy",
       title = "Experiment 1:\nData Visualisation Literacy x Axis Limit Interaction",
       subtitle =  "Estimated Marginal Means",
       ) + 
  theme_minimal(base_size = 10) +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) +
  geom_segment(aes(x = min(literacy),
                   xend = max(literacy),
                   y = 1,
                   yend = 1),
               color = "darkgrey",
               inherit.aes = F,
               arrow = arrow(length = unit(0.2, "cm")))
```

### Discussion

This experiment explored the consequences of including a graphical cue to a denominator value using bar charts' axes. In bar charts with extended axes, denominator information was available through the accompanying text *and* through the upper axis limit. Comparison with bar charts employing default axes, where denominator information was *only* available through text, reveals the contribution of a graphical cue to a denominator value. We observed that plotted values' magnitudes were interpreted as *greater* when a default axis limit was used, compared to an axis limit equal to the dataset's denominator value. Therefore, assessments of data were biased by the numerical context provided by axes.

In both conditions, there was a large proportion of magnitude ratings near the lower end of the rating scale. This indicates some attention to denominator information in the absence of a graphical cue. However, an increased presence of extreme high magnitude ratings in the condition with default axes suggests that the appearance of tall bars carried an implication of large values. These extreme ratings may indicate a failure to account for denominator information in the absence of a graphical cue. We investigate the role of denominator information further in Experiment 2.

## Experiment 2

### Introduction

Experiment 1 observed differences in interpretations of data presented using different axes limits. Overall, plotted data were associated with lower magnitudes when presenting using axes which extended to a denominator value. Compared to bar charts with extended axes, charts with no graphical cue to a denominator value elicited a wider range of responses. This variety appears to reflect differences in how the denominator information supplied in accompanying text is used in magnitude judgements. This raises questions about how external sources of denominator information might influence the interpretation of different chart designs.

In Experiment 2, we manipulate the presence of denominator information in accompanying text, in addition to manipulating axis limits. This experiment investigates how these textual and graphical cues inform assessments of data. This can reveal how different chart designs are interpreted with and without additional cues to numerical context. This 2x2 design provides an opportunity to replicate the primary finding from Experiment 1 and can also examine whether responses in the absence of denominator information resemble the previously observed pattern of extreme ratings.

This second experiment requires minor adaptations to materials and procedure. First, highly ambiguous trials without denominator information supplied in text may elicit unreliable random responses. Therefore, we collect additional *confidence ratings* to directly index this aspect of participants' evaluations. This provides a more comprehensive view of participants' cognitive representations. Second, when denominators are not supplied in text, participants may use denominator values supplied in previous trials to inform their judgements. A limited range of denominators (as in Experiment 1) would artificially diminish uncertainty regarding possible values, inhibiting authentic, spontaneous judgements. Therefore, we expand the range of denominator values in Experiment 2. Third, increasing the number of fillers (which depict relatively high magnitudes) to match the number of experimental items (which depict relatively low magnitudes) will avoid priming effects by ensuring high and low magnitudes seem equally plausible.

### Method

#### Materials

We generated bar charts in R (version 4.2.1) using *ggplot2* (version 3.4.4), *tidyverse* (version 1.3.2) and *ggh4x* (version 0.2.3).

Bar charts were generated using the same method as in Experiment 1. We used the same scenarios from Experiment 1, and generated 24 new scenarios for use as additional filler items, thus employing 32 experimental items and 32 filler items. To increase variation across datasets, we employed a wider range of denominators (200, 400, 600, and 800) meaning the plotted values for each scenario also differed from Experiment 1.

We added the word 'surveyed' or 'assessed' to the accompanying text for seven items where the absence of a denominator may have implied that data were collected for the entire population under study. For example, where the fictitious study concerned data collected in five towns, the final sentence read 'The graph shows, for each town, how many people *surveyed* used public transport regularly', to avoid the implication that the denominator was equal to an entire town's population. This ensured that the inclusion of denominator values was equally informative across all scenarios.

`r printnum(get_anomalies(e2), digits = 0)`% of datasets used were re-generated to ensure that the highest gridline of a default axis did not exceed the highest plotted value.

#### Design

We employed a within-participants 2x2 Latin-squared design with two factors: axis limits (default vs. extended) and denominator information (present vs. absent). Participants viewed 8 different charts for each combination of conditions (32 experimental trials total). The correspondence between scenarios and conditions was counterbalanced using four lists. However, all participants saw the same versions of the 32 filler items and six attention check items.

#### Participants

Participants were recruited using Prolific.co, using the same inclusion criteria as Experiment 1. Additionally, the experiment was not advertised to individuals who completed Experiment 1.

Data were returned by 208 participants. Per pre-registered exclusion criteria, eight participants' submissions were rejected because they answered more than one of six attention check questions incorrectly. Participants whose submissions were accepted received £5.00.

The final sample consisted of 200 participants (`r printnum(gender_e2$M, digits = 0)`% male, `r printnum(gender_e2$F, digits = 0)`% female, `r printnum(gender_e2$NB, digits = 0)`% non-binary, `r printnum(gender_e2$Another, digits = 1)`% other, `r printnum(gender_e2$Pnts, digits = 1)`% prefer not to say). Mean age was `r printnum(e2 %>% pull(ageResp.text) %>% mean(na.rm = T))` years (*SD* = `r printnum(e2 %>% pull(ageResp.text) %>% sd(na.rm = T))`)[^1]. The mean data visualisation literacy score was `r printnum(e2 %>% pull(literacy) %>% mean())` (*SD* = `r printnum(e2 %>% pull(literacy) %>% sd())`), out of a maximum of 30.

[^1]: Age data were unavailable for `r e2 %>% distinct(participant, .keep_all = TRUE) %>% pull(ageResp.text) %>% is.na() %>% sum()` participants

This experiment was approved by the University of Manchester's Division of Neuroscience and Experimental Psychology Ethics Committee (ethics code: 2023-11115-28428).

#### Procedure

The procedure was identical to Experiment 1, except for the addition of a confidence rating, where participants were asked 'How confident are you in your response?'. The anchors on the response scale were 'Not very confident' and 'Very confident'. @fig-e2-trial shows an example trial.

For attention check items, participants were asked to provide a specific response on the magnitude rating scale, and a random response on the confidence rating scale.

Average completion time was `r printnum(e2 %>% pull(total_duration) %>% mean(), digits = 1)` minutes.

```{r}
#| label: fig-e2-trial
#| include: true
#| out-width: "500px"
#| fig-scap: An example trial from Experiment 2, showing a bar chart with an extended axis limit.
#| fig-cap: An example trial from Experiment 2, showing a bar chart with an extended axis limit. Note the presence of an additional confidence rating scale.

include_graphics("images/trial_e2.png")
```

### Analysis

#### Magnitude Ratings

@fig-e2-mag shows the distribution of magnitude ratings for charts with default axes and extended axes, where denominators were absent from text, and where they were present.

```{r}
#| label: fig-e2-mag
#| include: true
#| message: false
#| out-width: "500px"
#| fig-asp: 1
#| fig-scap: "The distribution of magnitude ratings in response to default and extended axis limits, shown separately for trials where denominator values were *absent from* accompanying text, and trials where denominator values were *present in* accompanying text."
#| fig-cap: "The distribution of magnitude ratings in response to default and extended axis limits, shown separately for trials where denominator values were *absent from* accompanying text (top), and trials where denominator values were *present in* accompanying text (bottom). Each circle represents a participant's response to an individual bar chart."

denom_labs <- c("Denominator Present in Text", 
                 "Denominator Absent from Text")
names(denom_labs) <- c("pres", "abs")

e2 %>%
  ggplot(aes(x = mag_slider.response, 
             y = axis)) +
  geom_density_ridges(scale = 0,
                      colour = "lightgrey",
                      alpha = 0,
                      jittered_points = T,
                      position = position_raincloud(height = 0.3),
                      point_alpha = 0.05,
                      point_colour = "black",
                      point_size = 0.75) +
  geom_density_ridges(aes(height = after_stat(density)),
                      stat = "density",
                      scale = 0.5,
                      colour = "black",
                      fill = "darkgrey",
                      panel_scaling = FALSE) +
  geom_boxplot(outlier.shape=NA,
             width = 0.10,
             colour = "white",
             fill = "white",
             alpha = 0,
             lwd = 1,
             position = position_nudge(y=-.2)) +
  geom_boxplot(outlier.shape=NA,
               width = 0.09,
               colour = "black",
               fill = "white",
               alpha = 0.7,
               lwd = 0.5,
               position = position_nudge(y=-.2)) +
  scale_y_discrete(limits = c("extend", "default"),
                   labels = c("Extended\nAxis Limit", "Default\nAxis Limit")) + 
  labs(title = "Experiment 2:\nDistribution of Magnitude Ratings",
       subtitle =  "Density Plots, Boxplots, and Raw Data",
       y = NULL,
       x = NULL) + 
  scale_x_continuous(labels = c('Very low\nmagnitude', 'Very high\nmagnitude'),
                     breaks = c(1,2),
                     minor_breaks = c()) + 
  facet_wrap(vars(denominator), ncol = 1, labeller = labeller(denominator = denom_labs)) +
  theme_minimal(base_size = 10) +
  theme(aspect.ratio = 0.4)
```

```{r}
#| label: e2-mag
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_mag <- buildmer(mag_slider.response ~ axis*denominator +
                     (1 + axis*denominator | participant) + 
                     (1 + axis*denominator | item_no),
                   data = e2)
```

```{r}
summary_extract(e2_mag)
```

A mixed effects model revealed that charts with default axes elicited higher ratings compared to charts with extended axes (F(`r printnum(e2_mag_axis_NumDF)`, `r printnum(e2_mag_axis_DenDF)`) = `r printnum(e2_mag_axis_F.value)`, p `r printp(e2_mag_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_axis_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_mag_axis_Eta2_partial))` effect size) and charts not accompanied by a denominator in text elicited higher ratings than those accompanied by a denominator (F(`r printnum(e2_mag_denominator_NumDF)`, `r printnum(e2_mag_denominator_DenDF)`) = `r printnum(e2_mag_denominator_F.value)`, p `r printp(e2_mag_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_denominator_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_mag_denominator_Eta2_partial))` effect size).

Crucially, there was also a significant interaction between axis limits and denominator information: F(`r printnum(e2_mag_axis_denominator_NumDF)`, `r printnum(e2_mag_axis_denominator_DenDF)`) = `r printnum(e2_mag_axis_denominator_F.value)`, p `r printp(e2_mag_axis_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_axis_denominator_Eta2_partial)` (a `r paste(interpret_eta_squared(e2_mag_axis_denominator_Eta2_partial))` effect size). @fig-e2-mag-int plots this interaction.

```{r}
#| label: e2-mag-contrasts

e2_mag_emm <- emmeans(e2_mag@model, pairwise ~ axis * denominator, adjust = 'sidak') 
  
get_contrasts(e2_mag_emm, condition = "denominator")

e2_mag_emm_pres_d <- z_to_d(e2_mag_emm_pres_z.ratio, 
                        n = length(e2_mag@summary$residuals)/2, 
                        paired = FALSE, ci = 0.95, alternative = "two.sided")$d

e2_mag_emm_abs_d <- z_to_d(e2_mag_emm_abs_z.ratio, 
                        n = length(e2_mag@summary$residuals)/2, 
                        paired = FALSE, ci = 0.95, alternative = "two.sided")$d
```

```{r}
#| label: fig-e2-mag-int
#| out-width: "500px"
#| include: true
#| message: false
#| fig-scap: The interaction between axis limits and denominator information, for magnitude ratings.
#| fig-cap: The interaction between axis limits and denominator information, for magnitude ratings. Estimated marginal means are generated by the linear mixed model used in analysis. Translucent bars show 95% confidence intervals.

my_palette <- unname(palette.colors(palette = "Okabe-Ito")[2:3])

emmip(e2_mag@model, axis ~ denominator, CIs = T, 
      dotarg = list(shape = "circle", size = 2), 
      linearg = list(linetype = "solid", lwd = 1.5),
      CIarg = list(lwd = 3, alpha = 0.5)) +
  scale_x_discrete(limits = c('pres', 'abs'), 
                   labels = c('Present in text', 'Absent from text')) +
  scale_color_manual(limits = c('default', 'extend'), 
                       labels = c('Default', 'Extended'),
                   values = my_palette) +
  scale_y_continuous(limits = c(1,2), 
                     breaks = c(1,2), 
                     minor_breaks = seq(1,2,0.2),
                     labels = c('Very low\nmagnitude', 
                                'Very high\nmagnitude')) + 
  labs(color = "Axis Limit",
       y = "Magnitude Rating",
       x = "Denominator in Text",
       title = "Experiment 2\nAxis Limit x Denominator Information Interaction",
       subtitle =  "Estimated Marginal Means",
       ) + 
  theme_minimal(base_size = 10) +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) 
```

Pairwise comparisons conducted using *emmeans* [@lenth_emmeans_2021] revealed that charts with extended and default axes were rated differently when the denominator was present, replicating the effect from Experiment 1 (z = `r printnum(e2_mag_emm_pres_z.ratio)`, p `r printp(e2_mag_emm_pres_p.value, add_equals = T)`, Cohen's *d* = `r printnum(abs(e2_mag_emm_pres_d))`, a `r paste(interpret_cohens_d(e2_mag_emm_pres_d))` effect size), and also when the denominator was absent (z = `r printnum(e2_mag_emm_abs_z.ratio)`, p `r printp(e2_mag_emm_abs_p.value, add_equals = T)`, Cohen's *d* = `r printnum(abs(e2_mag_emm_abs_d))`, a `r paste(interpret_cohens_d(e2_mag_emm_abs_d))` effect size). Therefore, the interaction indicates that the *degree* to which a bar chart's axis affected interpretations varied according to whether the denominator was present or absent.

This model employed random intercepts for each participant, with random slopes for axis limits and denominator information, plus random intercepts for each scenario, with random slopes for denominator information. The model formula was as follows: `` `r print_formula(e2_mag)` ``

#### Magnitude Ratings and Data Visualisation Literacy

```{r}
#| label: e2-lit
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_mag_l <- lmer(add.terms(formula(e2_mag),
"literacy"),
              data = e2)
```

```{r}
#| label: e2-mag-lint
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_mag_lint <- buildmer(mag_slider.response ~ axis*denominator*literacy +
                     (1 + axis*denominator | participant) + 
                     (1 + axis*denominator*literacy | item_no),
                   buildmerControl=list(                         include='mag_slider.response ~ axis*denominator*literacy'),
                     data = e2)

emtrends(e2_mag_lint@model, pairwise ~ axis:denominator, var = "literacy")

emmip(e2_mag_lint@model, axis:denominator ~ literacy, cov.reduce = range) 

```

```{r}
#| label: e2-mag-statistics
summary_extract(e2_mag_l)
summary_extract(e2_mag_lint)

emtrends(e2_mag_lint@model, pairwise ~ axis:denominator, var = "literacy", infer = T)$emtrends %>%
  as_tibble() %>% 
  mutate(comb = paste0(axis, denominator)) %>%
  group_split(comb) %>% map(~ {
    vals <- as.list(.x)
    names(vals) <- paste0("e2_mag_lint", 
                          "_", 
                          .x$comb, 
                          "_", 
                          names(vals))
    list2env(vals, envir = globalenv())
})

e2_mag_lint_defaultpres_d <- z_to_d(e2_mag_lint_defaultpres_z.ratio, 
                        n = length(e2_mag_lint@summary$residuals)/2, 
                        paired = FALSE, ci = 0.95, alternative = "two.sided")$d

e2_mag_lint_extendpres_d <- z_to_d(e2_mag_lint_extendpres_z.ratio, 
                        n = length(e2_mag_lint@summary$residuals)/2, 
                        paired = FALSE, ci = 0.95, alternative = "two.sided")$d

e2_mag_lint_defaultabs_d <- z_to_d(e2_mag_lint_defaultabs_z.ratio, 
                        n = length(e2_mag_lint@summary$residuals)/2, 
                        paired = FALSE, ci = 0.95, alternative = "two.sided")$d

e2_mag_lint_extendabs_d <- z_to_d(e2_mag_lint_extendabs_z.ratio, 
                        n = length(e2_mag_lint@summary$residuals)/2, 
                        paired = FALSE, ci = 0.95, alternative = "two.sided")$d
```

Accounting for differences in data visualisation literacy did not eliminate the main effect of axis limits (F(`r printnum(e2_mag_l_axis_NumDF)`, `r printnum(e2_mag_l_axis_DenDF)`) = `r printnum(e2_mag_l_axis_F.value)`, p `r printp(e2_mag_l_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_l_axis_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_mag_l_axis_Eta2_partial))` effect size), the main effect of denominator information (F(`r printnum(e2_mag_l_denominator_NumDF)`, `r printnum(e2_mag_l_denominator_DenDF)`) = `r printnum(e2_mag_l_denominator_F.value)`, p `r printp(e2_mag_l_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_l_denominator_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_mag_l_denominator_Eta2_partial))` effect size), or the significant interaction: F(`r printnum(e2_mag_l_axis_denominator_NumDF)`, `r printnum(e2_mag_l_axis_denominator_DenDF)`) = `r printnum(e2_mag_l_axis_denominator_F.value)`, p `r printp(e2_mag_l_axis_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_l_axis_denominator_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_mag_l_axis_denominator_Eta2_partial))` effect size). This model employed the same random effects structure as above. The model formula was as follows: `` `r print_formula(e2_mag_l)` ``

However, an exploratory analysis revealed a significant three-way interaction between data visualisation literacy, axis limits, and denominator information: F(`r printnum(e2_mag_lint_axis_denominator_literacy_NumDF)`, `r printnum(e2_mag_lint_axis_denominator_literacy_DenDF)`) = `r printnum(e2_mag_lint_axis_denominator_literacy_F.value)`, p `r printp(e2_mag_lint_axis_denominator_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_mag_lint_axis_denominator_literacy_Eta2_partial)` (a `r paste(interpret_eta_squared(e2_mag_lint_axis_denominator_literacy_Eta2_partial))` effect size). Pairwise comparison reveals that differences in data visualisation literacy only predicted magnitude ratings for charts with default axes where the denominator was present in text. For this combination of conditions, magnitude ratings were lower for participants with higher data visualisation scores: z = `r printnum(e2_mag_lint_defaultpres_z.ratio)`, p `r printp(e2_mag_lint_defaultpres_p.value, add_equals = T)`, Cohen's *d* = `r printnum(abs(e2_mag_lint_defaultpres_d))`, (a `r paste(interpret_cohens_d(e2_mag_lint_defaultpres_d))` effect size). There were no other significant changes in magnitude ratings as a function of data visualisation literacy, for charts with extended axes where the denominator was present in text (z = `r printnum(e2_mag_lint_extendpres_z.ratio)`, p `r printp(e2_mag_lint_extendpres_p.value, add_equals = T)`, Cohen's *d* = `r printnum(abs(e2_mag_lint_extendpres_d))`, a `r paste(interpret_cohens_d(e2_mag_lint_extendpres_d))` effect size), for charts with default axes where the denominator was absent from text (z = `r printnum(e2_mag_lint_defaultabs_z.ratio)`, p `r printp(e2_mag_lint_defaultabs_p.value, add_equals = T)`, Cohen's *d* = `r printnum(abs(e2_mag_lint_defaultabs_d))`, a `r paste(interpret_cohens_d(e2_mag_lint_defaultabs_d))` effect size), or for charts with extended axes where the denominator was absent from text (z = `r printnum(e2_mag_lint_extendabs_z.ratio)`, p `r printp(e2_mag_lint_extendabs_p.value, add_equals = T)`, Cohen's *d* = `r printnum(abs(e2_mag_lint_extendabs_d))`, a `r paste(interpret_cohens_d(e2_mag_lint_extendabs_d))` effect size). This three-way interaction is shown in @fig-e2-mag-lint. This model employed random intercepts for participants, with random slopes for axis limits and denominator information, plus random slopes for scenarios. The model formula was as follows: `` `r paste(print_formula(e2_mag_lint))` ``.

```{r}
#| label: fig-e2-mag-lint
#| out-width: "500px"
#| include: true
#| warning: false
#| fig-scap: Three-way interaction between axis limits, denominator information, and data visualisation literacy, for magnitude ratings in Experiment 2.
#| fig-cap: Three-way interaction between axis limits, denominator information, and data visualisation literacy, for magnitude ratings in Experiment 2. The data displayed are based on the estimated marginal means from the interaction model. Note that this interaction is associated with a very small effect size, driven by the relationship between magnitude ratings and data visualisation literacy for bar charts with default axes where denominators were present in text.
denom_labs <- c("Denominator Present in Text", 
                 "Denominator Absent from Text")
names(denom_labs) <- c("pres", "abs")

emmip(e2_mag_lint@model, axis ~ literacy | denominator, cov.reduce = range, 
      linearg = list(linetype = "solid", lwd = 1.5)) +
  scale_color_manual(limits = c('default', 'extend'), 
                       labels = c('Default', 'Extended'),
                   values = my_palette) +
  scale_y_continuous(limits = c(1,2), 
                     breaks = c(1,2), 
                     minor_breaks = seq(1,2,0.2),
                     labels = c('Very low\nmagnitude', 
                                'Very high\nmagnitude')) + 
  labs(color = "Axis Limit",
       y = "Magnitude Rating",
       x = "Data Visualisation Literacy",
       title = "Experiment 2:\nInteraction Between Axis Limits, Denominator Information,\nand Data Visualisation Literacy",
       subtitle =  "Estimated Marginal Means") + 
  facet_wrap(vars(fct_rev(denominator)),
             labeller = as_labeller(denom_labs)) +
  geom_segment(aes(x = min(literacy),
                   xend = max(literacy),
                   y = 1,
                   yend = 1),
               color = "darkgrey",
               inherit.aes = F,
               arrow = arrow(length = unit(0.2, "cm"))) +
  theme_minimal(base_size = 10) +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5)) 
```

#### Confidence Ratings

```{r}
#| label: fig-e2-con
#| include: true
#| message: false
#| out-width: "500px"
#| fig-asp: 1
#| fig-scap: The distribution of confidence ratings in response to default and extended axis limits, shown separately for trials where denominator values were *absent from* accompanying text, and trials where denominator values were *present in* accompanying text.
#| fig-cap: The distribution of confidence ratings in response to default and extended axis limits, shown separately for trials where denominator values were *absent from* accompanying text (top), and trials where denominator values were *present in* accompanying text (bottom). Each circle represents a participant's response to an individual bar chart.

denom_labs <- c("Denominator Present in Text", 
                 "Denominator Absent from Text")
names(denom_labs) <- c("pres", "abs")

e2 %>%
  ggplot(aes(x = con_slider.response, 
             y = axis)) +
  geom_density_ridges(scale = 0,
                      colour = "lightgrey",
                      alpha = 0,
                      jittered_points = T,
                      position = position_raincloud(height = 0.3),
                      point_alpha = 0.05,
                      point_colour = "black",
                      point_size = 0.75) +
  geom_density_ridges(aes(height = after_stat(density)),
                      stat = "density",
                      scale = 0.5,
                      colour = "black",
                      fill = "darkgrey",
                      panel_scaling = FALSE) +
  geom_boxplot(outlier.shape=NA,
             width = 0.10,
             colour = "white",
             fill = "white",
             alpha = 0,
             lwd = 1,
             position = position_nudge(y=-.2)) +
  geom_boxplot(outlier.shape=NA,
               width = 0.09,
               colour = "black",
               fill = "white",
               alpha = 0.7,
               lwd = 0.5,
               position = position_nudge(y=-.2)) +
  scale_y_discrete(limits = c("extend", "default"),
                   labels = c("Extended\nAxis Limit", "Default\nAxis Limit")) + 
  labs(title = "Experiment 2 - Distribution of Confidence Ratings",
       subtitle =  "Density Plots, Boxplots, and Raw Data",
       y = NULL,
       x = NULL) + 
  scale_x_continuous(labels = c('Very\nconfident', 'Not very\nconfident'),
                     breaks = c(1,2),
                     minor_breaks = c()) + 
  facet_wrap(vars(denominator), ncol = 1, labeller = labeller(denominator = denom_labs)) +
  theme_minimal(base_size = 10) +
  theme(aspect.ratio = 0.4)
```

@fig-e2-con shows the distribution of confidence ratings for charts with default axes and extended axes, where denominators were absent from text, and where they were present.

```{r}
#| label: e2-con
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_con <- buildmer(con_slider.response ~ axis*denominator +
                     (1 + axis*denominator | participant) + 
                     (1 + axis*denominator | item_no),
                   data = e2)
```

```{r}
#| label: e2-con-anova
#| message: false

e2_con_summ <- anova(e2_con) %>% as_tibble(rownames = "FixEf", .name_repair = make.names) %>%
  rename("Pr" = "Pr..F.")
summary_extract(e2_con)
```

```{r}
#| label: e2-con-contrasts

e2_con_emm <- emmeans(e2_con@model, pairwise ~ axis * denominator, adjust = 'sidak') 
  
get_contrasts(e2_con_emm, condition = "denominator")

e2_con_emm_pres_d <- z_to_d(e2_con_emm_pres_z.ratio, 
                        n = length(e2_con@summary$residuals)/2, 
                        paired = FALSE, ci = 0.95, alternative = "two.sided")$d

e2_con_emm_abs_d <- z_to_d(e2_con_emm_abs_z.ratio, 
                        n = length(e2_con@summary$residuals)/2, 
                        paired = FALSE, ci = 0.95, alternative = "two.sided")$d
```

```{r}
#| label: fig-e2-con-int
#| include: true
#| out-width: "500px"
#| message: false
#| fig-scap: The interaction between axis limits and denominator information, for confidence ratings.
#| fig-cap: The interaction between axis limits and denominator information, for confidence ratings. Estimated marginal means are generated by the linear mixed model used in analysis. Translucent bars show 95% confidence intervals.

my_palette <- unname(palette.colors(palette = "Okabe-Ito")[2:3])

emmip(e2_con@model, denominator ~ axis, 
      CIs = T, 
      dotarg = list(shape = "circle", size = 2), 
      linearg = list(linetype = "solid", lwd = 1.5),
      CIarg = list(lwd = 3, alpha = 0.5)) +
  scale_color_manual(limits = c('abs', 'pres'), 
                   labels = c('Absent from text', 'Present in text'),
                   values = my_palette,
                   guide = guide_legend(reverse=T)) +
  scale_x_discrete(limits = c('extend', 'default'), 
                       labels = c('Extended', 'Default')) +
  scale_y_continuous(limits = c(1,2), 
                     breaks = c(1,2), 
                     minor_breaks = seq(1,2,0.2),
                     labels = c('Not very\nconfident', 
                                'Very\nconfident')) + 
  labs(x = "Axis Limit",
       y = "Confidence Rating",
       color = "Denominator in Text",
       title = "Experiment 2 - Confidence Ratings",
       subtitle =  "Estimated Marginal Means") + 
  theme_minimal(base_size = 10) 
```

A mixed effects model revealed a main effect associated with axis limits (F(`r printnum(e2_con_axis_NumDF)`, `r printnum(e2_con_axis_DenDF)`) = `r printnum(e2_con_axis_F.value)`, p `r printp(e2_con_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_axis_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_con_axis_Eta2_partial))` effect size); a main effect associated with denominator information (F(`r printnum(e2_con_denominator_NumDF)`, `r printnum(e2_con_denominator_DenDF)`) = `r printnum(e2_con_denominator_F.value)`, p `r printp(e2_con_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_denominator_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_con_denominator_Eta2_partial))` effect size); and an interaction between axis limits and denominator information (F(`r printnum(e2_con_denominator_axis_NumDF)`, `r printnum(e2_con_denominator_axis_DenDF)`) = `r printnum(e2_con_denominator_axis_F.value)`, p `r printp(e2_con_denominator_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_denominator_axis_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_con_denominator_axis_Eta2_partial))` effect size). This interaction consisted of a difference between extended and default charts when the denominator was absent from text (z = `r printnum(e2_con_emm_abs_z.ratio)`, p `r printp(e2_con_emm_abs_p.value, add_equals = T)`, Cohen's *d* = `r printnum(abs(e2_con_emm_abs_d))`, a `r paste(interpret_cohens_d(e2_con_emm_abs_d))` effect size), but no difference between charts when the denominator was present (z = `r printnum(e2_con_emm_pres_z.ratio)`, p `r printp(e2_con_emm_pres_p.value, add_equals = T)`, Cohen's *d* = `r printnum(abs(e2_con_emm_pres_d))`, a `r paste(interpret_cohens_d(e2_con_emm_pres_d))` effect size). However, it is clear from @fig-e2-con-int, as well as the partial $\eta^2$ values, that the effect sizes associated with both axis limits and the interaction are trivial.

This model employed random intercepts for participants with random slopes for axis limits and denominator information. The model formula was as follows: `` `r paste(print_formula(e2_con))` ``

#### Confidence Ratings and Data Visualisation Literacy

```{r}
#| label: e2-con-lit
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_con_l <- lmer(add.terms(formula(e2_con),
"literacy"),
              data = e2)
```

```{r}
#| label: e2-con-lint
#| eval: !expr params$eval_models
#| cache: !expr params$eval_models

e2_con_lint <- buildmer(con_slider.response ~ axis*denominator*literacy +
                     (1 + axis*denominator | participant) + 
                     (1 + axis*denominator*literacy | item_no),
                   buildmerControl=list(                         include='con_slider.response ~ axis*denominator*literacy'),
                     data = e2)

emtrends(e2_con_lint@model, pairwise ~ axis:denominator, var = "literacy")

emmip(e2_con_lint@model, axis:denominator ~ literacy, cov.reduce = range) 
```

```{r}
#| label: e2-con-statistics
summary_extract(e2_con_l)
summary_extract(e2_con_lint)
```

Accounting for differences in data visualisation literacy did not change the pattern of results for confidence ratings. There was a main effect associated with axis limits (F(`r printnum(e2_con_l_axis_NumDF)`, `r printnum(e2_con_l_axis_DenDF)`) = `r printnum(e2_con_l_axis_F.value)`, p `r printp(e2_con_l_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_l_axis_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_con_l_axis_Eta2_partial))` effect size); a main effect associated with denominator information (F(`r printnum(e2_con_l_denominator_NumDF)`, `r printnum(e2_con_l_denominator_DenDF)`) = `r printnum(e2_con_l_denominator_F.value)`, p `r printp(e2_con_l_denominator_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_l_denominator_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_con_l_denominator_Eta2_partial))` effect size); and an interaction between axis limits and denominator information (F(`r printnum(e2_con_l_denominator_axis_NumDF)`, `r printnum(e2_con_l_denominator_axis_DenDF)`) = `r printnum(e2_con_l_denominator_axis_F.value)`, p `r printp(e2_con_l_denominator_axis_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_l_denominator_axis_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_con_l_denominator_axis_Eta2_partial))` effect size). This model employed the same random effects structure as above. The model formula was as follows: `` `r paste(print_formula(e2_con_l))` ``

An exploratory analysis revealed that there was no interaction between data visualisation literacy and axis limits for confidence ratings (F(`r printnum(e2_con_lint_axis_literacy_NumDF)`, `r printnum(e2_con_lint_axis_literacy_DenDF)`) = `r printnum(e2_con_lint_axis_literacy_F.value)`, p `r printp(e2_con_lint_axis_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_lint_axis_literacy_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_con_lint_axis_literacy_Eta2_partial))` effect size); no interaction between data visualisation literacy and denominator information (F(`r printnum(e2_con_lint_denominator_literacy_NumDF)`, `r printnum(e2_con_lint_denominator_literacy_DenDF)`) = `r printnum(e2_con_lint_denominator_literacy_F.value)`, p `r printp(e2_con_lint_denominator_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_lint_denominator_literacy_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_con_lint_denominator_literacy_Eta2_partial))` effect size); and no three-way interaction between data visualisation literacy, axis limits, and denominator information (F(`r printnum(e2_con_lint_axis_denominator_literacy_NumDF)`, `r printnum(e2_con_lint_axis_denominator_literacy_DenDF)`) = `r printnum(e2_con_lint_axis_denominator_literacy_F.value)`, p `r printp(e2_con_lint_axis_denominator_literacy_p, add_equals = T)`, partial $\eta^2$ `r print_es(e2_con_lint_axis_denominator_literacy_Eta2_partial)`, a `r paste(interpret_eta_squared(e2_con_lint_axis_denominator_literacy_Eta2_partial))` effect size). This model employed random intercepts for participants, with random slopes for axis limits, denominator information, and the interaction between axis limits and denominator information. The model formula was as follows: `` `r paste(print_formula(e2_con_lint))` ``

### Discussion

This experiment manipulated bar charts' axis limits and the presence of denominator values in accompanying text. The results demonstrate that values presented in charts with default axis limits are associated with higher magnitude judgements than charts with extended axes, in both the presence and absence of denominator information. However, the absence of denominator information amplifies this bias. These results also suggest that extreme high magnitude ratings for default charts in the presence of a denominator value may be driven by a failure to incorporate that value into reasoning. Finally, confidence in judgements is reliably diminished by the omission of denominator information from text.

## General Discussion

Axis limits can be easily manipulated in common data visualisation software, in order to include a visual cue to denominator information. However, default axis limits are often based on plotted data only, so typically omit denominator information. We demonstrate that the magnitude of plotted values was interpreted as smaller in bar charts with axes that extended to the denominator value, compared to those employing default axis settings. The influence of axis limits was particularly large when no denominator information was included in the text accompanying a chart. This provides insight into the cognitive processing of magnitude, indicating that denominator information is an important aspect in interpreting absolute magnitude in bar charts.

In Experiment 1, we identified a framing effect, wherein charts with axes that accommodated a denominator value elicited smaller magnitude judgements compared to charts with default axes. In both conditions, the denominator was explicitly presented in the text. However, some extreme responses in the default condition appeared to disregard the denominator information. We conducted a further experiment in order to examine the interpretation of cues to magnitude in data visualisations. In Experiment 2, we examined how interpretations were affected by the absence of denominator information, thus capturing how this information was incorporated across chart designs.

Experiment 2 makes several additional contributions. First, this experiment replicated the main effect from Experiment 1. That is, we observed that magnitudes were interpreted as smaller when values were shown with an extended axis, rather than a default axis. Second, this experiment illustrated the impact of including the denominator in accompanying text. This cue affects viewers' interpretations differently depending on whether a chart's axis also incorporates the same value. Without denominator information in text, the magnitude of values plotted using *default axes* can be ambiguous. Accordingly, drastically higher ratings in the absence of denominator information illustrate the denominator's role in reducing ambiguity. Interpretation of values plotted using *extended axes* was affected to a lesser extent by the denominator's absence. Thus, the impact of a bar chart's axis is smaller when a denominator is included in accompanying text. This suggests axis limits provide a visual cue to denominator information when interpreting magnitudes.

Third, Experiment 2 replicated the pattern of responses observed in Experiment 1 for charts with default axes and accompanying denominator information. This pattern consists of a small number of higher magnitude ratings, in contrast to the general tendency for lower magnitude ratings. @fig-e2-mag reveals a close resemblance between the distribution of these higher ratings and the overall distribution of ratings for default charts *without* accompanying denominator information. This suggests that these extreme ratings may share a cause. Unusually high responses in the presence of denominator information likely result from failure to account for the denominator and a subsequent reliance on the chart's appearance. Analogous responses to charts without accompanying denominators in Experiment 2 can be considered an experimentally-induced instance of the same effect observed in Experiment 1.

Fourth, additional ratings collected in Experiment 2 provide insight into participants' confidence. Although analysis of these ratings indicated a main effect of axis limits and an interaction between denominator information and axis limits, the small effect sizes cast doubt over the practical significance of these effects. In spite of this, absence of a denominator clearly lowered confidence. This suggests that participants were hesitant to form magnitude judgements based solely on a bar chart's appearance. Inclusion of a denominator value in text was preferred regardless of graphical cues to context.

Regarding data visualisation literacy, in Experiment 1, the influence of axis limits on responses diminished as data visualisation literacy increased. In Experiment 2, the interaction between axis limits and denominator information also varied as a function of data visualisation literacy, but this was associated with a very small effect size. Therefore, there is some evidence to suggest that individuals with higher data visualisation literacy levels are less susceptible to the influence of design choices. However, the observed biases cannot be *fully* explained by accounting for differences in data visualisation literacy.

### Relationship to Prior Work

Our focus on judgements of values' magnitudes is noteworthy because the vast majority of related work has explored participants' judgements of *differences between* values [@okan_individual_2012; @okan_probability_2020; @okan_designing_2018; @stone_foregroundbackground_2003; @stone_salience_2018; @garcia-retamero_who_2010; @yang_truncating_2021; @witt_graph_2019; @correll_truncating_2020; @pandey_how_2015; @driessen_misleading_2022]. Responses to questions about values' magnitudes have often been obscured through inclusion in composite measures [e.g., @okan_designing_2018], or have been collected to assess comprehension, rather than interpretation [e.g., @garcia-retamero_who_2010]. As @stone_effects_2015 discuss, failing to consider interpretations of values' magnitudes reflects two issues. First, neglecting values' magnitudes overlooks a relevant aspect of numerical information. Second, neglecting participants' *interpretations* limits insight into decision-making, which is not simply governed by accurate retrieval of information [see @reyna_theory_2008].

Whereas much prior research has been limited to interpretation of risk information [@garcia-retamero_who_2010; @okan_individual_2012; @okan_probability_2020; @okan_designing_2018; @stone_foregroundbackground_2003; @stone_salience_2018; @stone_designing_2017; @stone_effects_2015], we demonstrate that biases in interpretation extend to a wide range of non-risk scenarios. This provides confidence that these findings are widely applicable, and using *multiple* trials per participant enhances statistical power. When generating charts that do not include denominator values, previous experiments [@garcia-retamero_who_2010; @okan_designing_2018] appear to have employed arbitrary axis limits. By employing axis limits based on *ggplot2*'s default settings, our materials reflect a common practice, enhancing our experiment's ecological validity.

We contribute to a large body of evidence illustrating biases in the interpretation of numerical information, specifically *framing effects* [@tversky_framing_1981]. Our results are consistent with research demonstrating that manipulating bar charts' axis limits influences interpretation of plotted values [@garcia-retamero_who_2010; @okan_designing_2018]. Furthermore, @okan_designing_2018 found that participants' perceptions of risk were influenced more by bar charts' axis limits when labels containing numerators and denominators were excluded. Similarly, we observed that interpretations of magnitude were influenced more by bar charts' axis limits when denominator values were omitted from accompanying text.

A previous study exploring interpretation of magnitude in bar charts observed different responses according to whether stacked bars or blank space conveyed alternative outcomes [@stone_designing_2017]. We demonstrate that manipulating the amount of blank space above bars can elicit different magnitude judgements, without plotting alternative outcomes explicitly. Earlier work investigating (in)consistency in the formats used to display numerators and denominators is also relevant. @stone_effects_2015 found that displaying a value using icons, accompanied by a denominator in text, increased impressions of that value's magnitude, compared to when both the value and denominator were presented in text. We too found higher ratings when values displayed using bars were only accompanied by a denominator in text, compared to when a corresponding graphical cue to the denominator value was also present.

According to Fuzzy Trace Theory, different interpretations can arise due to different gist-level representations, despite accurate comprehension of presented values [@reyna_theory_2008]. Therefore, access to denominator information in accompanying text did not prevent our chart designs influencing judgements. Encoding of gist is reported to be influenced by the appearance of graphical elements [@reyna_theory_2008]. This suggests that the taller bars in our default axis conditions contributed to impressions of greater magnitude, compared to shorter bars in our extended axis conditions. That charts with extended axes elicited lower magnitude ratings is also consistent with Stone et al.'s [-@stone_salience_2018] proportional reasoning account, which suggests that part-to-whole displays facilitate processing of a larger numerical context.

Our results are consistent with the finding that data visualisation literacy levels can help predict the influence of design choices, such as the efficacy of using icon arrays to reduce denominator neglect [@okan_individual_2012]. However, our results are also consistent with the finding that the impact of manipulations like ours (axis range, numerical labels) cannot be *fully explained* by adjusting for data visualisation literacy levels [@okan_designing_2018]. Therefore, other factors also contribute to the degree of bias observed. Numeracy is associated with decreased sensitivity to framing effects [@peters_numeracy_2006], so may also assist in understanding variation in response to visualisation designs.

### Implications

When conveying values' magnitudes, both axis limits and accompanying text warrant consideration from data visualisation designers. A bar chart produced using default settings does not elicit the same interpretation as a bar chart with an axis that incorporates a denominator value. Extending an axis in this manner increases consistency in judgements and may provide insurance against individuals who fail to account for accompanying denominator information. Similarly, where constraints prevent inclusion of a denominator value in text, an extended axis should facilitate viewers' recognition of this numerical context. We observed that confidence ratings were consistently high in the absence of a denominator in text, despite use of an extended axis. Explicitly providing denominator values in text, regardless of graphical cues, would therefore increase viewers' confidence in their judgements.

It is also worth considering situations which may accentuate the observed bias. High cognitive load exacerbates the numerosity bias [@pelham_easy_1994], therefore may also interfere with magnitude judgements. Even when denominator information is supplied in text, high cognitive load could prevent this information from informing interpretations. This would likely increase reliance on bar charts' appearances, as observed in Experiment 2. Additionally, assuming that an audience has knowledge of a dataset's denominator may increase biases in individuals who are unfamiliar with the topic.

### Limitations and Future Work

This work is concerned with visualisations intended to convey plotted values' magnitudes. However, design considerations will differ when conveying *differences* between values. In this case, axis ranges should be determined by the magnitude of the differences [@correll_truncating_2020; @witt_graph_2019; @yang_truncating_2021]. Consequently, our recommendations are not relevant for all communicative scenarios. However, maintaining awareness of the implication of plotted values' magnitudes may help avoid misinterpretation of data, even if this type of judgement is not a primary concern.

Our experiments apply best to controlled scenarios, such as surveys and experiments where all plotted values share the same denominator. These findings may also extend to datasets with unequal denominators, if bars are used to depict proportions or percentages, permitting use of a single meaningful axis limit. However, this design will not be suitable for plotting other types of dataset. We also acknowledge that proportions are not the only factor influencing magnitude judgements: subject matter is also likely to inform assessments. For example, bars clearly depicting one or two hours spent on administrative tasks within a 35-hour work week will still elicit some differences of opinion regarding whether these values are high or low. Future work should employ decision-making tasks to quantify the impact of axis limits on applied judgements.

All materials were produced using *ggplot2*. Therefore, our conclusions about default axis limits only pertain to bar charts created using this package's settings, though we expect other visualisation libraries' default settings to elicit similar responses, due to similarity in their behaviour. For uniformity in our materials, we only employed default charts where the highest gridline was positioned below the highest value, since this was the most common visual arrangement. We did not examine the minority of cases where the highest gridline exceeds the highest value. Whether this influences magnitude judgements could be explored in future experiments. Finally, it is important to recognise that defining axis limits according to the maximum highest plotted value is a necessary default setting, since denominator information is not always present in a dataset.

### Conclusion

In two experiments, we generated evidence on the effects of default and extended axis limits, illustrating the influential role of denominators on impressions of magnitude. We provide insight into the cognitive processes involved in interpreting plotted values' magnitudes in bar charts and offer recommendations for facilitating judgements. Framing effects demonstrate the power of presentation choices on the interpretation of numbers.
